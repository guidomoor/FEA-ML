{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPWIE2uMnKmoohL1sjTzK8F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guidomoor/FEA-ML/blob/main/NN_for_Ke.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ke prediction**\n",
        "\n",
        "the dataframe is extracted from single element simulations where multiple nodes are being displaced. The element is a 2D plain stress element fully integrated:\n",
        "\n",
        "4--------3\n",
        "\n",
        "1--------2\n",
        "\n",
        "U is a 8x1 array = [u11, u12, u21, u22, ..., u44]\n",
        "K is a 36x1 array = [K11, K12, ..., K36]"
      ],
      "metadata": {
        "id": "czBFk5AvAa7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "R3L1yGo4Zerk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Create a model that inherits nn.Module\n",
        " class Model(nn.Module):\n",
        "  #Input Layer (4 features of flower) -->\n",
        "  #Hidden Layer 1 (#of neurons) -->\n",
        "  #H2 --> Output\n",
        "  #(3 classes of flowers)\n",
        "  def __init__(self, in_features=8, h1=64, h2=64, h3=36, out_features=36):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(in_features, h1)\n",
        "    self.fc2 = nn.Linear(h1, h2)\n",
        "    self.fc3 = nn.Linear(h2, h3)\n",
        "    self.out = nn.Linear(h3, out_features)\n",
        "\n",
        "  #this function is pushing the information forward through the layers\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x)) #rectify linear unit function relu\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "LisjQxjIZn-A"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "uWX4KrYNaacv"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload a file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check the uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    print(f'Uploaded file: {filename}')\n",
        "    my_df = pd.read_csv(filename, header=None)  # Read the CSV file into a DataFrame\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "rKdKqeSObJYG",
        "outputId": "dab2153e-b884-411c-862a-ed124ca07316"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7107100a-ad40-45ec-bd6a-76bcb0a2b6c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7107100a-ad40-45ec-bd6a-76bcb0a2b6c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Final_NN_for_Ke.csv to Final_NN_for_Ke (7).csv\n",
            "Uploaded file: Final_NN_for_Ke (7).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_df\n"
      ],
      "metadata": {
        "id": "WuPJgBzne1Us",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "86b905a2-2a8d-483e-cc5c-e8356a0c4c70"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0    1     2     3     4     5     6     7             8   \\\n",
              "0     0.25 -0.5  0.25 -0.25  0.25  0.50 -0.25 -0.25  62264.898563   \n",
              "1     0.25 -0.5  0.25 -0.25  0.25  0.50 -0.25 -0.50  58670.700683   \n",
              "2     0.25 -0.5  0.25 -0.25  0.25  0.50 -0.50 -0.25  75187.016619   \n",
              "3     0.25 -0.5  0.25 -0.25  0.25  0.50 -0.50 -0.50  68536.956535   \n",
              "4     0.25 -0.5  0.25 -0.25  0.50  0.25 -0.25 -0.25  31505.311394   \n",
              "...    ...  ...   ...   ...   ...   ...   ...   ...           ...   \n",
              "4028  0.30 -1.0  0.30 -0.70  1.00  0.50 -0.45 -0.84  31967.745527   \n",
              "4029  0.30 -1.0  0.30 -0.70  1.00  0.50 -0.45 -0.84  31967.745527   \n",
              "4030  0.30 -1.0  0.30 -0.70  1.00  0.50 -0.45 -0.84  31967.745527   \n",
              "4031  0.30 -1.0  0.30 -0.70  1.00  0.50 -0.45 -0.84  31967.745527   \n",
              "4032  0.30 -1.0  0.30 -0.70  1.00  0.50 -0.45 -0.84  31967.745527   \n",
              "\n",
              "                9   ...           34            35           36            37  \\\n",
              "0     26270.604396  ... -1648.351648  43934.911243 -1648.351648 -32333.051564   \n",
              "1     20649.586145  ... -3089.324974  62094.435657  2783.594956 -28759.331076   \n",
              "2     29173.052974  ... -1139.271687  38390.850456 -3654.906737 -21128.397419   \n",
              "3     24318.071927  ... -2228.968061  54513.294712   -58.228020 -18214.505895   \n",
              "4     14881.879802  ... -5128.995125  52752.186475  7335.831226 -22441.431922   \n",
              "...            ...  ...          ...           ...          ...           ...   \n",
              "4028  11135.861179  ... -4451.324950  71903.503844  9134.504205 -20444.455186   \n",
              "4029  11135.861179  ... -4451.324950  71903.503844  9134.504205 -20444.455186   \n",
              "4030  11135.861179  ... -4451.324950  71903.503844  9134.504205 -20444.455186   \n",
              "4031  11135.861179  ... -4451.324950  71903.503844  9134.504205 -20444.455186   \n",
              "4032  11135.861179  ... -4451.324950  71903.503844  9134.504205 -20444.455186   \n",
              "\n",
              "                38            39           40           41            42  \\\n",
              "0     12637.362637 -11411.665258 -4120.879121  -190.194421  -6868.131868   \n",
              "1     13598.011521 -14965.327825 -5561.852447 -3513.546724 -10819.754031   \n",
              "2     12297.975997  -7283.285734 -3611.799160 -6382.763706  -5031.270100   \n",
              "3     13024.440246 -11064.395304 -4701.495533 -9364.945505  -8264.716692   \n",
              "4     14957.791622 -15788.401568 -7601.522598 -2278.936110 -14692.100250   \n",
              "...            ...           ...          ...          ...           ...   \n",
              "4028  16737.705583 -22118.112170 -6923.852422 -3092.608026 -18948.357366   \n",
              "4029  16737.705583 -22118.112170 -6923.852422 -3092.608026 -18948.357366   \n",
              "4030  16737.705583 -22118.112170 -6923.852422 -3092.608026 -18948.357366   \n",
              "4031  16737.705583 -22118.112170 -6923.852422 -3092.608026 -18948.357366   \n",
              "4032  16737.705583 -22118.112170 -6923.852422 -3092.608026 -18948.357366   \n",
              "\n",
              "                43  \n",
              "0     43934.911243  \n",
              "1     47238.205625  \n",
              "2     34794.446860  \n",
              "3     38643.846704  \n",
              "4     40508.769600  \n",
              "...            ...  \n",
              "4028  45655.175381  \n",
              "4029  45655.175381  \n",
              "4030  45655.175381  \n",
              "4031  45655.175381  \n",
              "4032  45655.175381  \n",
              "\n",
              "[4033 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43c73243-52ae-43a8-a272-a14e50b70e73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>62264.898563</td>\n",
              "      <td>26270.604396</td>\n",
              "      <td>...</td>\n",
              "      <td>-1648.351648</td>\n",
              "      <td>43934.911243</td>\n",
              "      <td>-1648.351648</td>\n",
              "      <td>-32333.051564</td>\n",
              "      <td>12637.362637</td>\n",
              "      <td>-11411.665258</td>\n",
              "      <td>-4120.879121</td>\n",
              "      <td>-190.194421</td>\n",
              "      <td>-6868.131868</td>\n",
              "      <td>43934.911243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>58670.700683</td>\n",
              "      <td>20649.586145</td>\n",
              "      <td>...</td>\n",
              "      <td>-3089.324974</td>\n",
              "      <td>62094.435657</td>\n",
              "      <td>2783.594956</td>\n",
              "      <td>-28759.331076</td>\n",
              "      <td>13598.011521</td>\n",
              "      <td>-14965.327825</td>\n",
              "      <td>-5561.852447</td>\n",
              "      <td>-3513.546724</td>\n",
              "      <td>-10819.754031</td>\n",
              "      <td>47238.205625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>75187.016619</td>\n",
              "      <td>29173.052974</td>\n",
              "      <td>...</td>\n",
              "      <td>-1139.271687</td>\n",
              "      <td>38390.850456</td>\n",
              "      <td>-3654.906737</td>\n",
              "      <td>-21128.397419</td>\n",
              "      <td>12297.975997</td>\n",
              "      <td>-7283.285734</td>\n",
              "      <td>-3611.799160</td>\n",
              "      <td>-6382.763706</td>\n",
              "      <td>-5031.270100</td>\n",
              "      <td>34794.446860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>68536.956535</td>\n",
              "      <td>24318.071927</td>\n",
              "      <td>...</td>\n",
              "      <td>-2228.968061</td>\n",
              "      <td>54513.294712</td>\n",
              "      <td>-58.228020</td>\n",
              "      <td>-18214.505895</td>\n",
              "      <td>13024.440246</td>\n",
              "      <td>-11064.395304</td>\n",
              "      <td>-4701.495533</td>\n",
              "      <td>-9364.945505</td>\n",
              "      <td>-8264.716692</td>\n",
              "      <td>38643.846704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>31505.311394</td>\n",
              "      <td>14881.879802</td>\n",
              "      <td>...</td>\n",
              "      <td>-5128.995125</td>\n",
              "      <td>52752.186475</td>\n",
              "      <td>7335.831226</td>\n",
              "      <td>-22441.431922</td>\n",
              "      <td>14957.791622</td>\n",
              "      <td>-15788.401568</td>\n",
              "      <td>-7601.522598</td>\n",
              "      <td>-2278.936110</td>\n",
              "      <td>-14692.100250</td>\n",
              "      <td>40508.769600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4028</th>\n",
              "      <td>0.30</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>31967.745527</td>\n",
              "      <td>11135.861179</td>\n",
              "      <td>...</td>\n",
              "      <td>-4451.324950</td>\n",
              "      <td>71903.503844</td>\n",
              "      <td>9134.504205</td>\n",
              "      <td>-20444.455186</td>\n",
              "      <td>16737.705583</td>\n",
              "      <td>-22118.112170</td>\n",
              "      <td>-6923.852422</td>\n",
              "      <td>-3092.608026</td>\n",
              "      <td>-18948.357366</td>\n",
              "      <td>45655.175381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4029</th>\n",
              "      <td>0.30</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>31967.745527</td>\n",
              "      <td>11135.861179</td>\n",
              "      <td>...</td>\n",
              "      <td>-4451.324950</td>\n",
              "      <td>71903.503844</td>\n",
              "      <td>9134.504205</td>\n",
              "      <td>-20444.455186</td>\n",
              "      <td>16737.705583</td>\n",
              "      <td>-22118.112170</td>\n",
              "      <td>-6923.852422</td>\n",
              "      <td>-3092.608026</td>\n",
              "      <td>-18948.357366</td>\n",
              "      <td>45655.175381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4030</th>\n",
              "      <td>0.30</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>31967.745527</td>\n",
              "      <td>11135.861179</td>\n",
              "      <td>...</td>\n",
              "      <td>-4451.324950</td>\n",
              "      <td>71903.503844</td>\n",
              "      <td>9134.504205</td>\n",
              "      <td>-20444.455186</td>\n",
              "      <td>16737.705583</td>\n",
              "      <td>-22118.112170</td>\n",
              "      <td>-6923.852422</td>\n",
              "      <td>-3092.608026</td>\n",
              "      <td>-18948.357366</td>\n",
              "      <td>45655.175381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4031</th>\n",
              "      <td>0.30</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>31967.745527</td>\n",
              "      <td>11135.861179</td>\n",
              "      <td>...</td>\n",
              "      <td>-4451.324950</td>\n",
              "      <td>71903.503844</td>\n",
              "      <td>9134.504205</td>\n",
              "      <td>-20444.455186</td>\n",
              "      <td>16737.705583</td>\n",
              "      <td>-22118.112170</td>\n",
              "      <td>-6923.852422</td>\n",
              "      <td>-3092.608026</td>\n",
              "      <td>-18948.357366</td>\n",
              "      <td>45655.175381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4032</th>\n",
              "      <td>0.30</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>31967.745527</td>\n",
              "      <td>11135.861179</td>\n",
              "      <td>...</td>\n",
              "      <td>-4451.324950</td>\n",
              "      <td>71903.503844</td>\n",
              "      <td>9134.504205</td>\n",
              "      <td>-20444.455186</td>\n",
              "      <td>16737.705583</td>\n",
              "      <td>-22118.112170</td>\n",
              "      <td>-6923.852422</td>\n",
              "      <td>-3092.608026</td>\n",
              "      <td>-18948.357366</td>\n",
              "      <td>45655.175381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4033 rows Ã— 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43c73243-52ae-43a8-a272-a14e50b70e73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43c73243-52ae-43a8-a272-a14e50b70e73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43c73243-52ae-43a8-a272-a14e50b70e73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dfba3b75-b869-4a9c-8432-544360f07ea8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfba3b75-b869-4a9c-8432-544360f07ea8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dfba3b75-b869-4a9c-8432-544360f07ea8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2e867ff6-49ae-49b7-b8db-013f7c7ed1fc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('my_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2e867ff6-49ae-49b7-b8db-013f7c7ed1fc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('my_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "my_df"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming my_df has 44 columns\n",
        "X = my_df.iloc[:, :8]  # Select the first 8 columns (Coord): input\n",
        "y = my_df.iloc[:, 8:]   # Select the last 36 columns (Ke): output\n",
        "#convert to numpy arrays\n",
        "#Data used in the NN\n",
        "X = X.values\n",
        "y = y.values"
      ],
      "metadata": {
        "id": "b_-ESzexfven"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bPZ3xi0E03Z8"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "2o3Cwlv4gr4L"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test Slip\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "KSJSEmzahC20"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your datasets to PyTorch tensors\n",
        "X_train = torch.FloatTensor(X_train)  # Inputs should be Float\n",
        "X_test = torch.FloatTensor(X_test)    # Inputs should be Float\n",
        "\n",
        "# If y_train and y_test are initially NumPy arrays\n",
        "y_train = np.array(y_train, dtype=float)  # Ensure they are float arrays\n",
        "y_test = np.array(y_test, dtype=float)    # Ensure they are float arrays\n",
        "\n",
        "# Convert to PyTorch FloatTensor\n",
        "y_train = torch.FloatTensor(y_train)  # Convert to FloatTensor\n",
        "y_test = torch.FloatTensor(y_test)    # Convert to FloatTensor\n",
        "\n"
      ],
      "metadata": {
        "id": "Bnh-wJd9hOPs"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalized Dataset**"
      ],
      "metadata": {
        "id": "ItQlD6OQC7mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-Max Normalization for Inputs\n",
        "X_train_min = X_train.min(dim=0, keepdim=True).values  # Min of each feature in training set\n",
        "X_train_max = X_train.max(dim=0, keepdim=True).values  # Max of each feature in training set\n",
        "\n",
        "X_train_normalized = (X_train - X_train_min) / (X_train_max - X_train_min)\n",
        "X_test_normalized = (X_test - X_train_min) / (X_train_max - X_train_min)  # Apply training stats to test\n",
        "\n",
        "# Or, Standardization (Z-score normalization) for Inputs\n",
        "X_train_mean = X_train.mean(dim=0, keepdim=True)\n",
        "X_train_std = X_train.std(dim=0, keepdim=True)\n",
        "\n",
        "X_train_standardized = (X_train - X_train_mean) / X_train_std\n",
        "X_test_standardized = (X_test - X_train_mean) / X_train_std  # Apply training stats to test\n",
        "\n",
        "# Min-Max Normalization for Labels\n",
        "y_train_min = y_train.min()\n",
        "y_train_max = y_train.max()\n",
        "\n",
        "y_train_normalized = (y_train - y_train_min) / (y_train_max - y_train_min)\n",
        "y_test_normalized = (y_test - y_train_min) / (y_train_max - y_train_min)  # Apply training stats to test\n",
        "\n",
        "# Or, Standardization (Z-score normalization) for Labels\n",
        "y_train_mean = y_train.mean()\n",
        "y_train_std = y_train.std()\n",
        "\n",
        "y_train_standardized = (y_train - y_train_mean) / y_train_std\n",
        "y_test_standardized = (y_test - y_train_mean) / y_train_std  # Apply training\n",
        "\n",
        "# Example: Using Min-Max normalized inputs and labels\n",
        "X_train = X_train_normalized\n",
        "X_test = X_test_normalized\n",
        "y_train = y_train_normalized\n",
        "y_test = y_test_normalized"
      ],
      "metadata": {
        "id": "uAYjqVvNA2Vs"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean and Variance:\n",
        "Mean = X_train_mean\n",
        "Var = X_train_std\n",
        "print(Mean)\n",
        "print(Var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu4T4x5KDcEu",
        "outputId": "1497ef05-22d0-4ec3-cccd-c312f26053e0"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5797, -0.5994,  0.5797, -0.5949,  0.6126,  0.5884, -0.5707, -0.6113]])\n",
            "tensor([[0.3175, 0.3322, 0.3175, 0.3080, 0.3226, 0.3060, 0.3113, 0.3101]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the criterion of model to measure the error\n",
        "criterion = nn.MSELoss()  # Use MSE loss for regression\n",
        "#Choose an Optimizer - Adam Optimizer, learning rate (lr).\n",
        "#learning rate is used in case the error does not go down\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "QenM3pAjhU9Z"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model:\n",
        "#Epochs: (one run through all the training data in the network)\n",
        "epochs = 1000\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "  #go forward and get a prediction\n",
        "  y_pred = model.forward(X_train)\n",
        "\n",
        "  #Measure the loss/error\n",
        "  loss = criterion(y_pred, y_train) #predicted values vs the y_train\n",
        "\n",
        "  #Keep Track of losses\n",
        "  losses.append(loss.detach().numpy())\n",
        "\n",
        "  #Print the losses\n",
        "  if i % 10 == 0:\n",
        "    print(f'Epoch: {i} Loss: {loss}')\n",
        "\n",
        "  #Do back propagation: take error of forward propagation and feed it backwords to fine tune the weights\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "WLp2cRUBhYo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12af6877-dfd8-4a4e-a9c9-8d0c0853ff79"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 0.09130657464265823\n",
            "Epoch: 10 Loss: 0.06735768169164658\n",
            "Epoch: 20 Loss: 0.03948234021663666\n",
            "Epoch: 30 Loss: 0.019281547516584396\n",
            "Epoch: 40 Loss: 0.007155183237046003\n",
            "Epoch: 50 Loss: 0.0022959536872804165\n",
            "Epoch: 60 Loss: 0.0007254758384078741\n",
            "Epoch: 70 Loss: 0.0003445998299866915\n",
            "Epoch: 80 Loss: 0.000296665879432112\n",
            "Epoch: 90 Loss: 0.00023948083980940282\n",
            "Epoch: 100 Loss: 0.00019428000086918473\n",
            "Epoch: 110 Loss: 0.00017279788153246045\n",
            "Epoch: 120 Loss: 0.0001560564269311726\n",
            "Epoch: 130 Loss: 0.00014284960343502462\n",
            "Epoch: 140 Loss: 0.00013299773854669183\n",
            "Epoch: 150 Loss: 0.00012578758469317108\n",
            "Epoch: 160 Loss: 0.00012028597120661288\n",
            "Epoch: 170 Loss: 0.000115322953206487\n",
            "Epoch: 180 Loss: 0.00010806520003825426\n",
            "Epoch: 190 Loss: 0.00010028993710875511\n",
            "Epoch: 200 Loss: 9.212628356181085e-05\n",
            "Epoch: 210 Loss: 8.48543641041033e-05\n",
            "Epoch: 220 Loss: 7.912681030575186e-05\n",
            "Epoch: 230 Loss: 7.484171510441229e-05\n",
            "Epoch: 240 Loss: 7.14707639417611e-05\n",
            "Epoch: 250 Loss: 6.84929545968771e-05\n",
            "Epoch: 260 Loss: 6.591608689632267e-05\n",
            "Epoch: 270 Loss: 6.359693361446261e-05\n",
            "Epoch: 280 Loss: 6.140267214505002e-05\n",
            "Epoch: 290 Loss: 5.905318903387524e-05\n",
            "Epoch: 300 Loss: 5.651219908031635e-05\n",
            "Epoch: 310 Loss: 5.416709973360412e-05\n",
            "Epoch: 320 Loss: 5.201760359341279e-05\n",
            "Epoch: 330 Loss: 5.010057793697342e-05\n",
            "Epoch: 340 Loss: 4.8497473471798e-05\n",
            "Epoch: 350 Loss: 4.710470966529101e-05\n",
            "Epoch: 360 Loss: 4.586117574945092e-05\n",
            "Epoch: 370 Loss: 4.482300573727116e-05\n",
            "Epoch: 380 Loss: 4.386863292893395e-05\n",
            "Epoch: 390 Loss: 4.302297384128906e-05\n",
            "Epoch: 400 Loss: 4.22717712353915e-05\n",
            "Epoch: 410 Loss: 4.159622039878741e-05\n",
            "Epoch: 420 Loss: 4.098897989024408e-05\n",
            "Epoch: 430 Loss: 4.0478946175426245e-05\n",
            "Epoch: 440 Loss: 3.989798278780654e-05\n",
            "Epoch: 450 Loss: 3.9388272853102535e-05\n",
            "Epoch: 460 Loss: 3.8958289223955944e-05\n",
            "Epoch: 470 Loss: 3.8480109651573e-05\n",
            "Epoch: 480 Loss: 3.816924072452821e-05\n",
            "Epoch: 490 Loss: 3.7624853575835004e-05\n",
            "Epoch: 500 Loss: 3.7240002711769193e-05\n",
            "Epoch: 510 Loss: 3.686041236505844e-05\n",
            "Epoch: 520 Loss: 3.6499863199424e-05\n",
            "Epoch: 530 Loss: 3.614604429458268e-05\n",
            "Epoch: 540 Loss: 3.579450640245341e-05\n",
            "Epoch: 550 Loss: 3.561206176527776e-05\n",
            "Epoch: 560 Loss: 3.515730713843368e-05\n",
            "Epoch: 570 Loss: 3.4770135243888944e-05\n",
            "Epoch: 580 Loss: 3.4444114135112613e-05\n",
            "Epoch: 590 Loss: 3.412855221540667e-05\n",
            "Epoch: 600 Loss: 3.480100349406712e-05\n",
            "Epoch: 610 Loss: 3.360084883752279e-05\n",
            "Epoch: 620 Loss: 3.3227446692762896e-05\n",
            "Epoch: 630 Loss: 3.295954593340866e-05\n",
            "Epoch: 640 Loss: 3.2653671951266006e-05\n",
            "Epoch: 650 Loss: 3.237679629819468e-05\n",
            "Epoch: 660 Loss: 3.20938415825367e-05\n",
            "Epoch: 670 Loss: 3.1815394322620705e-05\n",
            "Epoch: 680 Loss: 3.153919169562869e-05\n",
            "Epoch: 690 Loss: 3.1247345759766176e-05\n",
            "Epoch: 700 Loss: 3.0950395739637315e-05\n",
            "Epoch: 710 Loss: 3.0654806323582307e-05\n",
            "Epoch: 720 Loss: 3.0363540645339526e-05\n",
            "Epoch: 730 Loss: 3.0076251277932897e-05\n",
            "Epoch: 740 Loss: 2.9818784241797403e-05\n",
            "Epoch: 750 Loss: 2.9531835025409237e-05\n",
            "Epoch: 760 Loss: 2.9287575671332888e-05\n",
            "Epoch: 770 Loss: 2.8906652005389333e-05\n",
            "Epoch: 780 Loss: 2.859006417565979e-05\n",
            "Epoch: 790 Loss: 2.825703086273279e-05\n",
            "Epoch: 800 Loss: 2.7921927539864555e-05\n",
            "Epoch: 810 Loss: 2.815993138938211e-05\n",
            "Epoch: 820 Loss: 2.7295011022943072e-05\n",
            "Epoch: 830 Loss: 2.6915144189842977e-05\n",
            "Epoch: 840 Loss: 2.647529800015036e-05\n",
            "Epoch: 850 Loss: 2.596574449853506e-05\n",
            "Epoch: 860 Loss: 2.544521885283757e-05\n",
            "Epoch: 870 Loss: 2.4896182367228903e-05\n",
            "Epoch: 880 Loss: 2.437733746774029e-05\n",
            "Epoch: 890 Loss: 2.3666598281124607e-05\n",
            "Epoch: 900 Loss: 2.2929152692086063e-05\n",
            "Epoch: 910 Loss: 2.2213063857634552e-05\n",
            "Epoch: 920 Loss: 2.151842818420846e-05\n",
            "Epoch: 930 Loss: 2.1569263481069356e-05\n",
            "Epoch: 940 Loss: 2.0355220840428956e-05\n",
            "Epoch: 950 Loss: 1.9860117390635423e-05\n",
            "Epoch: 960 Loss: 1.945235999301076e-05\n",
            "Epoch: 970 Loss: 1.9075376258115284e-05\n",
            "Epoch: 980 Loss: 1.8745566194411367e-05\n",
            "Epoch: 990 Loss: 1.8459548300597817e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Loss\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.ylabel('Loss/error')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "fJNsQXmxkFix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "5831b062-f61e-44ba-b330-4e0c273578c4"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Model on Test Data Set\n",
        "with torch.no_grad(): #turns off backpropagation\n",
        "  y_eval = model.forward(X_test)\n",
        "  loss = criterion(y_eval, y_test)\n",
        "\n",
        "loss"
      ],
      "metadata": {
        "id": "PmyHAEiylrrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafda235-21bc-462f-9d46-39a8557f4c9a"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.4162e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient calculation\n",
        "with torch.no_grad():\n",
        "    # Get predictions\n",
        "    y_preds = model(X_test)\n",
        "\n",
        "    # Calculate Mean Absolute Error (MAE)\n",
        "    mae = torch.mean(torch.abs(y_preds - y_test))\n",
        "    print(f'MAE: {mae.item():.4f}')\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE)\n",
        "    mse = torch.mean((y_preds - y_test) ** 2)\n",
        "    print(f'MSE: {mse.item():.4f}')\n",
        "\n",
        "    # Calculate R-squared\n",
        "    ss_total = torch.sum((y_test - torch.mean(y_test)) ** 2)\n",
        "    ss_residual = torch.sum((y_test - y_preds) ** 2)\n",
        "    r_squared = 1 - (ss_residual / ss_total)\n",
        "    print(f'R-squared: {r_squared.item():.4f}')\n"
      ],
      "metadata": {
        "id": "h7WHYWMEp2FQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e1fd77-99b4-4a84-c5f7-70115a3cf0d4"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.0022\n",
            "MSE: 0.0000\n",
            "R-squared: 0.9835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new random input\n",
        "new_test = torch.tensor([[0.25,\t0.2,\t0.2,\t0.2,\t0.250000000000000,\t0.25,\t0.2,\t0.2]])\n",
        "#Feed into the NN, like the X_test\n",
        "#with torch.no_grad():\n",
        "#  print(model(new_test))\n",
        "\n",
        "\n",
        "# Feed the input data into the model (without gradient tracking)\n",
        "with torch.no_grad():\n",
        "    prediction_normalized = model(new_test)\n",
        "\n",
        "# Denormalize the prediction to get the real values (back to the original scale)\n",
        "prediction_real = prediction_normalized * (y_train_max - y_train_min) + y_train_min\n",
        "\n",
        "# Print the real output (denormalized)\n",
        "print(prediction_real)"
      ],
      "metadata": {
        "id": "e5SV9xJVqSpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0138b3-1b32-483d-fc02-af820e24e919"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 40558.1406,  15399.6250,  45025.3750, -22985.9375,    495.9375,\n",
            "          42776.9375,    416.7969,   7621.9688, -16738.5156,  45830.1406,\n",
            "         -17225.7344, -15724.9844,   7901.7031,   2707.5938,  35480.9219,\n",
            "         -14481.2812, -17228.5312,    276.9531, -25037.6562,  12147.1562,\n",
            "          36165.2031,   2776.6875,  -1512.3281, -22123.0781,  16522.5938,\n",
            "         -23717.4844,   -363.9844,  43668.4062,   -728.7031, -26835.5938,\n",
            "          15986.4531, -22632.6875,   -668.2812,   2832.8750, -16602.6094,\n",
            "          40367.6875]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting all weights and biases\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:  # Only if you want trainable parameters\n",
        "        print(f'Layer: {name}, Weights: {param.data.numpy()}')\n"
      ],
      "metadata": {
        "id": "LkyK9RTrAD1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ea35d8-d515-4ccd-f541-be66451db674"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: fc1.weight, Weights: [[ 0.25161088  0.28385282 -0.10152226  0.31779453 -0.09223342  0.06259073\n",
            "  -0.17671143  0.19998108]\n",
            " [ 0.32936093 -0.21838292  0.3249957   0.11618964  0.29723254  0.08484596\n",
            "   0.21374375  0.00985615]\n",
            " [ 0.27586514  0.05068088 -0.16173682  0.10218589 -0.14851151 -0.04666248\n",
            "  -0.13956097  0.24295071]\n",
            " [-0.2790845  -0.16299176 -0.09983455 -0.21258192  0.03336947 -0.3491973\n",
            "   0.31929728 -0.30033237]\n",
            " [ 0.28188682  0.07967262 -0.10586657  0.2415613   0.07144839  0.3051645\n",
            "   0.06187642 -0.0888126 ]\n",
            " [ 0.11242742 -0.06979685  0.16622902  0.34189412  0.23413713 -0.12855962\n",
            "   0.23244928  0.0891972 ]\n",
            " [ 0.19747795 -0.19791517 -0.3320548  -0.11404548 -0.24098979  0.3040752\n",
            "   0.12047897  0.16187482]\n",
            " [ 0.06521732  0.07732931  0.23009601 -0.29911807 -0.01268351 -0.28674686\n",
            "   0.13099715 -0.0378322 ]\n",
            " [ 0.12844443 -0.0500658   0.31334454 -0.18447927 -0.17565882 -0.17691946\n",
            "   0.34430125  0.14304663]\n",
            " [ 0.36862662 -0.2505546  -0.32226148 -0.23432077 -0.19485964  0.17231527\n",
            "   0.1666951   0.33154985]\n",
            " [-0.20548446 -0.24701117  0.16468717 -0.11732784  0.17533627 -0.12522748\n",
            "   0.22776037 -0.2743449 ]\n",
            " [-0.18206756  0.14258002  0.07109682 -0.05534219  0.21880697  0.24068424\n",
            "  -0.20863166 -0.15794042]\n",
            " [ 0.3010626  -0.15078402 -0.14801341 -0.35670844 -0.2232523   0.07254715\n",
            "  -0.06654967 -0.24643406]\n",
            " [ 0.33885017 -0.0871111   0.03060354 -0.31076828 -0.13727316 -0.5677197\n",
            "   0.4005187   0.22187725]\n",
            " [ 0.2630769  -0.28321424 -0.07807846 -0.00475988  0.02059024 -0.28661788\n",
            "   0.03688499 -0.09642289]\n",
            " [ 0.00097979 -0.13155834 -0.02449975 -0.23957828 -0.24267733 -0.20626368\n",
            "  -0.12102041 -0.27905294]\n",
            " [ 0.2987722  -0.04354535  0.30652452  0.15572196 -0.26764387  0.2700863\n",
            "  -0.06428362 -0.09115677]\n",
            " [-0.38196337 -0.33285782  0.01266635 -0.11305999  0.10789038 -0.14752516\n",
            "   0.26492384 -0.2856641 ]\n",
            " [-0.05564203  0.08812845  0.18792982  0.30305403  0.34042212 -0.2571179\n",
            "   0.10560715 -0.13240865]\n",
            " [-0.04634556 -0.25846708  0.31443536 -0.21909116  0.17637622  0.12605894\n",
            "   0.08313679 -0.19503362]\n",
            " [ 0.30209222  0.07345378  0.02621077 -0.3188398   0.13881756 -0.05974128\n",
            "  -0.1730411   0.30083594]\n",
            " [ 0.05676603 -0.14272659 -0.2010054  -0.02067957  0.19679075 -0.12549415\n",
            "  -0.13970715 -0.11621529]\n",
            " [-0.26360247  0.13545783  0.27419293 -0.3183661   0.08732226  0.19563977\n",
            "   0.08030988 -0.11535033]\n",
            " [ 0.19130775  0.20683324  0.13897657 -0.02706106 -0.06894162  0.04791689\n",
            "  -0.02559877 -0.07351287]\n",
            " [ 0.22328523  0.30197603 -0.03770944 -0.08336558  0.01685173 -0.0476512\n",
            "   0.07862524  0.09465612]\n",
            " [-0.42416307 -0.22946066  0.19469234  0.19361874 -0.10542922 -0.15271974\n",
            "  -0.14217974 -0.23119852]\n",
            " [-0.13083164  0.08751279  0.20984676  0.1326613  -0.3400068  -0.23462093\n",
            "  -0.08592723  0.3126139 ]\n",
            " [ 0.02623286 -0.112841    0.12135899 -0.12464501 -0.2454312   0.23574166\n",
            "  -0.17372647 -0.07286602]\n",
            " [-0.35423732  0.24670345  0.2653434   0.14252883 -0.24274847 -0.3208088\n",
            "  -0.27317294  0.27371725]\n",
            " [ 0.14923045  0.25645027  0.1647034   0.11889953  0.01881372 -0.3360926\n",
            "  -0.27310586 -0.33541602]\n",
            " [ 0.14473131 -0.17358339 -0.07115353 -0.20347182 -0.06442576 -0.24884321\n",
            "  -0.23101732  0.11727748]\n",
            " [ 0.03697411  0.2369214   0.02862588 -0.19346619  0.04121828 -0.04021573\n",
            "   0.06938083 -0.1637495 ]\n",
            " [ 0.20170996 -0.23335214  0.18160224  0.17403537  0.26639986 -0.2593304\n",
            "   0.26994792 -0.15314582]\n",
            " [ 0.13644442  0.34496927 -0.04461063  0.01787595 -0.0443623  -0.24410246\n",
            "   0.19170107 -0.32597032]\n",
            " [ 0.1956262   0.24791092  0.31049806 -0.09384134 -0.29223174  0.08091053\n",
            "   0.18410052 -0.3596165 ]\n",
            " [-0.00316839 -0.13656537  0.04615935 -0.05811864 -0.06802642 -0.05159035\n",
            "  -0.23971793  0.33773142]\n",
            " [ 0.2634846  -0.06136157 -0.0731734  -0.1784301  -0.35465333 -0.3614855\n",
            "   0.11146289 -0.20861006]\n",
            " [-0.22729133 -0.02758536 -0.11773722 -0.11438186  0.01136009 -0.07499307\n",
            "  -0.12173282 -0.16928345]\n",
            " [-0.27375892  0.30445057 -0.12751493  0.10437832 -0.08341476  0.05706168\n",
            "   0.34047526  0.17449021]\n",
            " [-0.3510343   0.10680925  0.29096293  0.06959914  0.20455018  0.31691292\n",
            "  -0.0788147   0.04049956]\n",
            " [-0.24573201 -0.07285926  0.2618359   0.18124767 -0.2237247  -0.28350917\n",
            "  -0.24160554 -0.34891394]\n",
            " [-0.34986106 -0.09738249  0.16155991  0.05175657 -0.27581492 -0.19687243\n",
            "   0.16038275 -0.27280822]\n",
            " [-0.08570624  0.26722494 -0.20580272  0.08631366  0.21816118 -0.2054926\n",
            "   0.00559256 -0.31781617]\n",
            " [-0.24474679 -0.3520567   0.38252604  0.02654012 -0.60566914  0.24924038\n",
            "   0.12186693  0.3611595 ]\n",
            " [ 0.2493699   0.17349634 -0.3699215   0.01319662  0.20406367 -0.03311093\n",
            "  -0.22874494  0.3203283 ]\n",
            " [-0.07766575 -0.13898495 -0.26417455  0.1096097   0.2083949   0.127466\n",
            "   0.13967292 -0.16597503]\n",
            " [-0.32546368  0.01461092  0.32709733  0.2213062  -0.18561819 -0.00074199\n",
            "  -0.24743024 -0.14320433]\n",
            " [ 0.0551838   0.19193871  0.28402853 -0.32341874  0.23750284 -0.2510222\n",
            "   0.13708061  0.29752418]\n",
            " [ 0.0136119   0.33544442 -0.2925987  -0.11004835  0.22494288 -0.05586166\n",
            "  -0.04709978 -0.12267833]\n",
            " [ 0.2394999   0.17184666  0.1090894  -0.18689059 -0.26198092  0.05856299\n",
            "   0.11134949 -0.15539917]\n",
            " [-0.15209119  0.30300307 -0.02500385  0.03159225  0.07680993 -0.14959902\n",
            "  -0.26405108 -0.13000657]\n",
            " [-0.17406383  0.16169697 -0.09726835  0.02912419  0.51764643  0.09505445\n",
            "   0.2892795  -0.12609279]\n",
            " [-0.14441483  0.12994517 -0.23556383 -0.23111928 -0.01707651 -0.12931593\n",
            "  -0.26504412  0.20971335]\n",
            " [ 0.41863137  0.22070809  0.07275876 -0.17833033  0.04118368  0.20540251\n",
            "   0.25079876  0.14919616]\n",
            " [-0.13050453  0.20682687 -0.2722961   0.2427182  -0.03629655  0.13286301\n",
            "  -0.0664203   0.05605691]\n",
            " [-0.09025716  0.27360433  0.0073948   0.29778534  0.3694468  -0.13989364\n",
            "  -0.23506807  0.3018837 ]\n",
            " [ 0.26879108 -0.27749735 -0.03558903 -0.35618418 -0.2894185   0.06002801\n",
            "   0.0857658   0.06665499]\n",
            " [-0.06317855  0.31511575  0.08359659 -0.22165346 -0.07362942  0.24009982\n",
            "   0.14166829 -0.05124611]\n",
            " [ 0.11804385 -0.1639833  -0.30824637 -0.16456474  0.33905834  0.29985029\n",
            "   0.33030427  0.22456974]\n",
            " [ 0.26709175 -0.04732303 -0.19453493  0.17665526 -0.18320526 -0.2386011\n",
            "  -0.11290163  0.07419645]\n",
            " [ 0.18200809 -0.13732332 -0.2080896   0.0476919  -0.2083961  -0.23018497\n",
            "   0.18429038 -0.05939152]\n",
            " [ 0.31101212  0.34634572  0.09368997  0.12789547  0.08670501  0.0091514\n",
            "  -0.02030478  0.01081565]\n",
            " [ 0.12737891  0.32972246 -0.09627341 -0.13897708 -0.07670647 -0.14667796\n",
            "   0.065968    0.2732917 ]\n",
            " [ 0.26639313  0.15239486 -0.2702687  -0.19889833 -0.07767972 -0.06516843\n",
            "   0.01914839 -0.33370346]]\n",
            "Layer: fc1.bias, Weights: [ 0.10552311 -0.2192021  -0.21439052 -0.2939381   0.33403373 -0.30430034\n",
            "  0.29334238 -0.04580601 -0.00978434  0.2665911  -0.05994327  0.26372227\n",
            "  0.23666921 -0.22222748  0.31758672  0.06674346  0.10985961  0.07318895\n",
            "  0.12112761 -0.17707959 -0.05770096  0.3414514   0.25840414  0.02146606\n",
            " -0.33678353  0.18757781 -0.26983738  0.27577516 -0.20180085 -0.0571758\n",
            " -0.07846858  0.33814943  0.35298944  0.06436004  0.20126152  0.39675668\n",
            "  0.2608207  -0.12210017 -0.05682791  0.14858924 -0.09647329  0.1549328\n",
            "  0.09749741 -0.12374805  0.13150544  0.16490312  0.18475592  0.35903084\n",
            "  0.2717817   0.35324585  0.06118208 -0.21956387 -0.24802732 -0.1738244\n",
            " -0.29597154 -0.14911987 -0.33376136 -0.3242567  -0.19265622 -0.3485449\n",
            " -0.21701548  0.14482911  0.3101532  -0.11509953]\n",
            "Layer: fc2.weight, Weights: [[-0.00492964  0.07543509 -0.0749378  ... -0.0323742  -0.07330598\n",
            "  -0.02761524]\n",
            " [ 0.02550693 -0.11710946  0.10913919 ... -0.05844738 -0.05965042\n",
            "  -0.10484327]\n",
            " [ 0.0188912  -0.13020681  0.03592749 ...  0.05913128  0.02387518\n",
            "  -0.12148278]\n",
            " ...\n",
            " [ 0.00045891 -0.10685729  0.09669832 ...  0.13608962  0.00727585\n",
            "  -0.02294306]\n",
            " [ 0.08569211  0.00403693  0.1173528  ...  0.01999821 -0.09171519\n",
            "  -0.03418271]\n",
            " [ 0.02930921 -0.10045022  0.03440022 ... -0.02821867 -0.03621269\n",
            "   0.09459405]]\n",
            "Layer: fc2.bias, Weights: [ 0.11199389  0.0355287  -0.01347042  0.02641317  0.126152    0.05603395\n",
            " -0.06234129  0.0244684  -0.00701953  0.00629102 -0.09519369 -0.01743279\n",
            "  0.1110969  -0.04017473  0.10135603  0.0997237  -0.10455456  0.06091816\n",
            " -0.09516534 -0.01929768  0.03477923  0.0283464   0.04960106 -0.01201448\n",
            "  0.1447627  -0.07556414  0.01031992 -0.00735955  0.078       0.01276472\n",
            "  0.0692364   0.05837484  0.05933572  0.01811097  0.07952667  0.101216\n",
            " -0.00413493 -0.00906354  0.05119828  0.12003961 -0.11792611  0.0278501\n",
            " -0.12259428 -0.03578897  0.0545851   0.05393178  0.02152357  0.14407796\n",
            "  0.12779987  0.11512906 -0.13588798 -0.04546721  0.03085752  0.1376778\n",
            " -0.01892743  0.02611241  0.08397176  0.02896005 -0.01557349  0.15364802\n",
            " -0.0027892   0.11613324 -0.12188649 -0.02233179]\n",
            "Layer: fc3.weight, Weights: [[ 0.11728272 -0.01210177  0.07887426 ... -0.10199957 -0.11325128\n",
            "   0.07085551]\n",
            " [-0.03144373  0.07096836  0.00194191 ...  0.08664513  0.03427117\n",
            "   0.06889893]\n",
            " [ 0.09364674  0.01990932  0.07564235 ... -0.03094478  0.0651511\n",
            "   0.08829641]\n",
            " ...\n",
            " [-0.04215858  0.11968611  0.04252303 ...  0.09264445  0.08585006\n",
            "   0.0570945 ]\n",
            " [-0.10279372  0.1060079   0.07354193 ... -0.11074356 -0.0476815\n",
            "   0.09100943]\n",
            " [-0.05734523 -0.11723286  0.00470151 ...  0.05343504  0.11575858\n",
            "  -0.08372428]]\n",
            "Layer: fc3.bias, Weights: [ 0.07939795  0.05848568 -0.11112506 -0.10740362  0.07900468 -0.0344036\n",
            "  0.06325477 -0.08644249  0.10937754 -0.06925315  0.03602063  0.02541247\n",
            " -0.06690262 -0.08320189  0.00489637 -0.02033163  0.09055045 -0.01365868\n",
            "  0.01055991 -0.07710725 -0.05941691  0.11822104 -0.05049764 -0.10952935\n",
            "  0.01137837 -0.0274164   0.02744056 -0.08522412  0.00984843 -0.03318686\n",
            " -0.08320118  0.05337328  0.02701285  0.04406769  0.11212502  0.05234387]\n",
            "Layer: out.weight, Weights: [[ 0.07427366 -0.00118028 -0.15987003 ...  0.10702376  0.10484397\n",
            "   0.12434916]\n",
            " [-0.08368738  0.10072604  0.13183059 ... -0.1018746  -0.01794566\n",
            "   0.19519928]\n",
            " [ 0.08740779  0.10183359 -0.13355333 ... -0.02458163  0.16876017\n",
            "   0.0357754 ]\n",
            " ...\n",
            " [ 0.04481257  0.03827624 -0.08692823 ...  0.15955524  0.09155922\n",
            "   0.07151078]\n",
            " [-0.04554548 -0.0731817  -0.1617785  ...  0.15178558 -0.02139146\n",
            "   0.18116784]\n",
            " [ 0.09392546 -0.00517737  0.08343601 ...  0.00928121  0.1754984\n",
            "  -0.08952862]]\n",
            "Layer: out.bias, Weights: [ 0.14166056  0.10601851 -0.11052939  0.07524806  0.04392438  0.0725345\n",
            " -0.01862771  0.10715492  0.12321865  0.16350557  0.01049236 -0.12315805\n",
            "  0.19868009  0.07813799  0.18349163  0.07053857  0.03141683  0.11482332\n",
            "  0.1260891   0.02793351  0.07660624  0.02600718  0.12994146  0.0951199\n",
            "  0.00066368  0.19576524  0.19091281  0.15150404  0.06055883  0.02049576\n",
            " -0.03574279  0.14385138 -0.09565813 -0.09077007  0.08729681 -0.11405923]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access weights directly from each layer\n",
        "weights_fc1 = model.fc1.weight.data.numpy()\n",
        "weights_fc2 = model.fc2.weight.data.numpy()\n",
        "weights_fc3 = model.fc3.weight.data.numpy()\n",
        "weights_out = model.out.weight.data.numpy()\n",
        "\n",
        "print(\"Weights from fc1:\", weights_fc1)\n",
        "#print(\"Weights from fc2:\", weights_fc2)\n",
        "#print(\"Weights from fc3:\", weights_fc3)\n",
        "#print(\"Weights from output layer:\", weights_out)\n",
        "\n",
        "# Save weights to text files\n",
        "#np.savetxt('weights_fc1.txt', weights_fc1, fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('weights_fc2.txt', weights_fc2, fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('weights_fc3.txt', weights_fc3, fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('weights_output.txt', weights_out, fmt='%.6f', delimiter=',')"
      ],
      "metadata": {
        "id": "JT4--XSfNmst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1562d8d8-76c5-4f09-cfec-4d99318a67bd"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights from fc1: [[ 0.25161088  0.28385282 -0.10152226  0.31779453 -0.09223342  0.06259073\n",
            "  -0.17671143  0.19998108]\n",
            " [ 0.32936093 -0.21838292  0.3249957   0.11618964  0.29723254  0.08484596\n",
            "   0.21374375  0.00985615]\n",
            " [ 0.27586514  0.05068088 -0.16173682  0.10218589 -0.14851151 -0.04666248\n",
            "  -0.13956097  0.24295071]\n",
            " [-0.2790845  -0.16299176 -0.09983455 -0.21258192  0.03336947 -0.3491973\n",
            "   0.31929728 -0.30033237]\n",
            " [ 0.28188682  0.07967262 -0.10586657  0.2415613   0.07144839  0.3051645\n",
            "   0.06187642 -0.0888126 ]\n",
            " [ 0.11242742 -0.06979685  0.16622902  0.34189412  0.23413713 -0.12855962\n",
            "   0.23244928  0.0891972 ]\n",
            " [ 0.19747795 -0.19791517 -0.3320548  -0.11404548 -0.24098979  0.3040752\n",
            "   0.12047897  0.16187482]\n",
            " [ 0.06521732  0.07732931  0.23009601 -0.29911807 -0.01268351 -0.28674686\n",
            "   0.13099715 -0.0378322 ]\n",
            " [ 0.12844443 -0.0500658   0.31334454 -0.18447927 -0.17565882 -0.17691946\n",
            "   0.34430125  0.14304663]\n",
            " [ 0.36862662 -0.2505546  -0.32226148 -0.23432077 -0.19485964  0.17231527\n",
            "   0.1666951   0.33154985]\n",
            " [-0.20548446 -0.24701117  0.16468717 -0.11732784  0.17533627 -0.12522748\n",
            "   0.22776037 -0.2743449 ]\n",
            " [-0.18206756  0.14258002  0.07109682 -0.05534219  0.21880697  0.24068424\n",
            "  -0.20863166 -0.15794042]\n",
            " [ 0.3010626  -0.15078402 -0.14801341 -0.35670844 -0.2232523   0.07254715\n",
            "  -0.06654967 -0.24643406]\n",
            " [ 0.33885017 -0.0871111   0.03060354 -0.31076828 -0.13727316 -0.5677197\n",
            "   0.4005187   0.22187725]\n",
            " [ 0.2630769  -0.28321424 -0.07807846 -0.00475988  0.02059024 -0.28661788\n",
            "   0.03688499 -0.09642289]\n",
            " [ 0.00097979 -0.13155834 -0.02449975 -0.23957828 -0.24267733 -0.20626368\n",
            "  -0.12102041 -0.27905294]\n",
            " [ 0.2987722  -0.04354535  0.30652452  0.15572196 -0.26764387  0.2700863\n",
            "  -0.06428362 -0.09115677]\n",
            " [-0.38196337 -0.33285782  0.01266635 -0.11305999  0.10789038 -0.14752516\n",
            "   0.26492384 -0.2856641 ]\n",
            " [-0.05564203  0.08812845  0.18792982  0.30305403  0.34042212 -0.2571179\n",
            "   0.10560715 -0.13240865]\n",
            " [-0.04634556 -0.25846708  0.31443536 -0.21909116  0.17637622  0.12605894\n",
            "   0.08313679 -0.19503362]\n",
            " [ 0.30209222  0.07345378  0.02621077 -0.3188398   0.13881756 -0.05974128\n",
            "  -0.1730411   0.30083594]\n",
            " [ 0.05676603 -0.14272659 -0.2010054  -0.02067957  0.19679075 -0.12549415\n",
            "  -0.13970715 -0.11621529]\n",
            " [-0.26360247  0.13545783  0.27419293 -0.3183661   0.08732226  0.19563977\n",
            "   0.08030988 -0.11535033]\n",
            " [ 0.19130775  0.20683324  0.13897657 -0.02706106 -0.06894162  0.04791689\n",
            "  -0.02559877 -0.07351287]\n",
            " [ 0.22328523  0.30197603 -0.03770944 -0.08336558  0.01685173 -0.0476512\n",
            "   0.07862524  0.09465612]\n",
            " [-0.42416307 -0.22946066  0.19469234  0.19361874 -0.10542922 -0.15271974\n",
            "  -0.14217974 -0.23119852]\n",
            " [-0.13083164  0.08751279  0.20984676  0.1326613  -0.3400068  -0.23462093\n",
            "  -0.08592723  0.3126139 ]\n",
            " [ 0.02623286 -0.112841    0.12135899 -0.12464501 -0.2454312   0.23574166\n",
            "  -0.17372647 -0.07286602]\n",
            " [-0.35423732  0.24670345  0.2653434   0.14252883 -0.24274847 -0.3208088\n",
            "  -0.27317294  0.27371725]\n",
            " [ 0.14923045  0.25645027  0.1647034   0.11889953  0.01881372 -0.3360926\n",
            "  -0.27310586 -0.33541602]\n",
            " [ 0.14473131 -0.17358339 -0.07115353 -0.20347182 -0.06442576 -0.24884321\n",
            "  -0.23101732  0.11727748]\n",
            " [ 0.03697411  0.2369214   0.02862588 -0.19346619  0.04121828 -0.04021573\n",
            "   0.06938083 -0.1637495 ]\n",
            " [ 0.20170996 -0.23335214  0.18160224  0.17403537  0.26639986 -0.2593304\n",
            "   0.26994792 -0.15314582]\n",
            " [ 0.13644442  0.34496927 -0.04461063  0.01787595 -0.0443623  -0.24410246\n",
            "   0.19170107 -0.32597032]\n",
            " [ 0.1956262   0.24791092  0.31049806 -0.09384134 -0.29223174  0.08091053\n",
            "   0.18410052 -0.3596165 ]\n",
            " [-0.00316839 -0.13656537  0.04615935 -0.05811864 -0.06802642 -0.05159035\n",
            "  -0.23971793  0.33773142]\n",
            " [ 0.2634846  -0.06136157 -0.0731734  -0.1784301  -0.35465333 -0.3614855\n",
            "   0.11146289 -0.20861006]\n",
            " [-0.22729133 -0.02758536 -0.11773722 -0.11438186  0.01136009 -0.07499307\n",
            "  -0.12173282 -0.16928345]\n",
            " [-0.27375892  0.30445057 -0.12751493  0.10437832 -0.08341476  0.05706168\n",
            "   0.34047526  0.17449021]\n",
            " [-0.3510343   0.10680925  0.29096293  0.06959914  0.20455018  0.31691292\n",
            "  -0.0788147   0.04049956]\n",
            " [-0.24573201 -0.07285926  0.2618359   0.18124767 -0.2237247  -0.28350917\n",
            "  -0.24160554 -0.34891394]\n",
            " [-0.34986106 -0.09738249  0.16155991  0.05175657 -0.27581492 -0.19687243\n",
            "   0.16038275 -0.27280822]\n",
            " [-0.08570624  0.26722494 -0.20580272  0.08631366  0.21816118 -0.2054926\n",
            "   0.00559256 -0.31781617]\n",
            " [-0.24474679 -0.3520567   0.38252604  0.02654012 -0.60566914  0.24924038\n",
            "   0.12186693  0.3611595 ]\n",
            " [ 0.2493699   0.17349634 -0.3699215   0.01319662  0.20406367 -0.03311093\n",
            "  -0.22874494  0.3203283 ]\n",
            " [-0.07766575 -0.13898495 -0.26417455  0.1096097   0.2083949   0.127466\n",
            "   0.13967292 -0.16597503]\n",
            " [-0.32546368  0.01461092  0.32709733  0.2213062  -0.18561819 -0.00074199\n",
            "  -0.24743024 -0.14320433]\n",
            " [ 0.0551838   0.19193871  0.28402853 -0.32341874  0.23750284 -0.2510222\n",
            "   0.13708061  0.29752418]\n",
            " [ 0.0136119   0.33544442 -0.2925987  -0.11004835  0.22494288 -0.05586166\n",
            "  -0.04709978 -0.12267833]\n",
            " [ 0.2394999   0.17184666  0.1090894  -0.18689059 -0.26198092  0.05856299\n",
            "   0.11134949 -0.15539917]\n",
            " [-0.15209119  0.30300307 -0.02500385  0.03159225  0.07680993 -0.14959902\n",
            "  -0.26405108 -0.13000657]\n",
            " [-0.17406383  0.16169697 -0.09726835  0.02912419  0.51764643  0.09505445\n",
            "   0.2892795  -0.12609279]\n",
            " [-0.14441483  0.12994517 -0.23556383 -0.23111928 -0.01707651 -0.12931593\n",
            "  -0.26504412  0.20971335]\n",
            " [ 0.41863137  0.22070809  0.07275876 -0.17833033  0.04118368  0.20540251\n",
            "   0.25079876  0.14919616]\n",
            " [-0.13050453  0.20682687 -0.2722961   0.2427182  -0.03629655  0.13286301\n",
            "  -0.0664203   0.05605691]\n",
            " [-0.09025716  0.27360433  0.0073948   0.29778534  0.3694468  -0.13989364\n",
            "  -0.23506807  0.3018837 ]\n",
            " [ 0.26879108 -0.27749735 -0.03558903 -0.35618418 -0.2894185   0.06002801\n",
            "   0.0857658   0.06665499]\n",
            " [-0.06317855  0.31511575  0.08359659 -0.22165346 -0.07362942  0.24009982\n",
            "   0.14166829 -0.05124611]\n",
            " [ 0.11804385 -0.1639833  -0.30824637 -0.16456474  0.33905834  0.29985029\n",
            "   0.33030427  0.22456974]\n",
            " [ 0.26709175 -0.04732303 -0.19453493  0.17665526 -0.18320526 -0.2386011\n",
            "  -0.11290163  0.07419645]\n",
            " [ 0.18200809 -0.13732332 -0.2080896   0.0476919  -0.2083961  -0.23018497\n",
            "   0.18429038 -0.05939152]\n",
            " [ 0.31101212  0.34634572  0.09368997  0.12789547  0.08670501  0.0091514\n",
            "  -0.02030478  0.01081565]\n",
            " [ 0.12737891  0.32972246 -0.09627341 -0.13897708 -0.07670647 -0.14667796\n",
            "   0.065968    0.2732917 ]\n",
            " [ 0.26639313  0.15239486 -0.2702687  -0.19889833 -0.07767972 -0.06516843\n",
            "   0.01914839 -0.33370346]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access biases directly from each layer\n",
        "bias_fc1 = model.fc1.bias.data.numpy()\n",
        "bias_fc2 = model.fc2.bias.data.numpy()\n",
        "bias_fc3 = model.fc3.bias.data.numpy()\n",
        "bias_out = model.out.bias.data.numpy()\n",
        "\n",
        "print(\"Biases from fc1:\", bias_fc1)\n",
        "print(\"Biases from fc2:\", bias_fc2)\n",
        "print(\"Biases from fc3:\", bias_fc3)\n",
        "print(\"Biases from output layer:\", bias_out)\n",
        "\n",
        "#np.savetxt('Biases1.txt', bias_fc1.reshape(1, -1), fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('Biases2.txt', bias_fc2.reshape(1, -1), fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('Biases3.txt', bias_fc3.reshape(1, -1), fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('BiasesOut.txt', bias_out.reshape(1, -1), fmt='%.6f', delimiter=',')"
      ],
      "metadata": {
        "id": "m15nsjH-NrWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a403969a-027a-4f1c-c909-6fa8703d543e"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biases from fc1: [ 0.10552311 -0.2192021  -0.21439052 -0.2939381   0.33403373 -0.30430034\n",
            "  0.29334238 -0.04580601 -0.00978434  0.2665911  -0.05994327  0.26372227\n",
            "  0.23666921 -0.22222748  0.31758672  0.06674346  0.10985961  0.07318895\n",
            "  0.12112761 -0.17707959 -0.05770096  0.3414514   0.25840414  0.02146606\n",
            " -0.33678353  0.18757781 -0.26983738  0.27577516 -0.20180085 -0.0571758\n",
            " -0.07846858  0.33814943  0.35298944  0.06436004  0.20126152  0.39675668\n",
            "  0.2608207  -0.12210017 -0.05682791  0.14858924 -0.09647329  0.1549328\n",
            "  0.09749741 -0.12374805  0.13150544  0.16490312  0.18475592  0.35903084\n",
            "  0.2717817   0.35324585  0.06118208 -0.21956387 -0.24802732 -0.1738244\n",
            " -0.29597154 -0.14911987 -0.33376136 -0.3242567  -0.19265622 -0.3485449\n",
            " -0.21701548  0.14482911  0.3101532  -0.11509953]\n",
            "Biases from fc2: [ 0.11199389  0.0355287  -0.01347042  0.02641317  0.126152    0.05603395\n",
            " -0.06234129  0.0244684  -0.00701953  0.00629102 -0.09519369 -0.01743279\n",
            "  0.1110969  -0.04017473  0.10135603  0.0997237  -0.10455456  0.06091816\n",
            " -0.09516534 -0.01929768  0.03477923  0.0283464   0.04960106 -0.01201448\n",
            "  0.1447627  -0.07556414  0.01031992 -0.00735955  0.078       0.01276472\n",
            "  0.0692364   0.05837484  0.05933572  0.01811097  0.07952667  0.101216\n",
            " -0.00413493 -0.00906354  0.05119828  0.12003961 -0.11792611  0.0278501\n",
            " -0.12259428 -0.03578897  0.0545851   0.05393178  0.02152357  0.14407796\n",
            "  0.12779987  0.11512906 -0.13588798 -0.04546721  0.03085752  0.1376778\n",
            " -0.01892743  0.02611241  0.08397176  0.02896005 -0.01557349  0.15364802\n",
            " -0.0027892   0.11613324 -0.12188649 -0.02233179]\n",
            "Biases from fc3: [ 0.07939795  0.05848568 -0.11112506 -0.10740362  0.07900468 -0.0344036\n",
            "  0.06325477 -0.08644249  0.10937754 -0.06925315  0.03602063  0.02541247\n",
            " -0.06690262 -0.08320189  0.00489637 -0.02033163  0.09055045 -0.01365868\n",
            "  0.01055991 -0.07710725 -0.05941691  0.11822104 -0.05049764 -0.10952935\n",
            "  0.01137837 -0.0274164   0.02744056 -0.08522412  0.00984843 -0.03318686\n",
            " -0.08320118  0.05337328  0.02701285  0.04406769  0.11212502  0.05234387]\n",
            "Biases from output layer: [ 0.14166056  0.10601851 -0.11052939  0.07524806  0.04392438  0.0725345\n",
            " -0.01862771  0.10715492  0.12321865  0.16350557  0.01049236 -0.12315805\n",
            "  0.19868009  0.07813799  0.18349163  0.07053857  0.03141683  0.11482332\n",
            "  0.1260891   0.02793351  0.07660624  0.02600718  0.12994146  0.0951199\n",
            "  0.00066368  0.19576524  0.19091281  0.15150404  0.06055883  0.02049576\n",
            " -0.03574279  0.14385138 -0.09565813 -0.09077007  0.08729681 -0.11405923]\n"
          ]
        }
      ]
    }
  ]
}