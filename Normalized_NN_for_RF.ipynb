{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guidomoor/FEA-ML/blob/main/Normalized_NN_for_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czBFk5AvAa7e"
      },
      "source": [
        "# **RF prediction**\n",
        "\n",
        "the dataframe is extracted from single element simulations where multiple nodes are being displaced (here in the picture nodes 3 and 4). The element is a 2D plain stress element fully integrated:\n",
        "\n",
        "4--------3\n",
        "         \n",
        "1--------2\n",
        "\n",
        "\n",
        "*   U is a 8x1 array = [u11, u12, u21, u22, ..., u44]\n",
        "*   COORD is a 8x1 array = [coord11, coord12, coord21, coord22, ..., coord44]\n",
        "*   RF is a 8x1 array = [F11, F12, ..., F44]\n",
        "\n",
        "In total is therefore a 16 inputs - 8 outputs system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "R3L1yGo4Zerk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LisjQxjIZn-A"
      },
      "outputs": [],
      "source": [
        " #Create a model that inherits nn.Module\n",
        " class Model(nn.Module):\n",
        "  #Input Layer (4 features of flower) -->\n",
        "  #Hidden Layer 1 (#of neurons) -->\n",
        "  #H2 --> Output\n",
        "  #(3 classes of flowers)\n",
        "  def __init__(self, in_features=16, h1=32, h2=64, h3=32, out_features=8):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(in_features, h1)\n",
        "    self.fc2 = nn.Linear(h1, h2)\n",
        "    self.fc3 = nn.Linear(h2, h3)\n",
        "    self.out = nn.Linear(h3, out_features)\n",
        "\n",
        "  #this function is pushing the information forward through the layers\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x)) #rectify linear unit function relu\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.out(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uWX4KrYNaacv"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rKdKqeSObJYG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "90247b46-47d3-42d8-af3d-e0d5ad7709a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78989d69-ebc6-4f6f-b261-227dbe665afe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78989d69-ebc6-4f6f-b261-227dbe665afe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving NN_for_RF_normalized.csv to NN_for_RF_normalized (1).csv\n",
            "Uploaded file: NN_for_RF_normalized (1).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload a file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check the uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    print(f'Uploaded file: {filename}')\n",
        "    my_df = pd.read_csv(filename, header=None)  # Read the CSV file into a DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WuPJgBzne1Us",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "e92b03f5-fc9c-4ee6-e770-6bacaec77007"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0    1    2    3    4    5     6     7             8             9   \\\n",
              "0     0.5 -0.5  0.5 -0.5  0.5  0.5 -0.50 -0.50 -1.190476e-32 -9.157509e-34   \n",
              "1     0.5 -0.5  0.5 -0.5  0.5  0.5 -0.50 -0.50 -1.167582e-32  2.060440e-33   \n",
              "2     0.5 -0.5  0.5 -0.5  0.5  0.5 -0.50 -0.50 -1.144689e-32  5.036630e-33   \n",
              "3     0.5 -0.5  0.5 -0.5  0.5  0.5 -0.50 -0.50 -1.121795e-32  8.012820e-33   \n",
              "4     0.5 -0.5  0.5 -0.5  0.5  0.5 -0.50 -0.50 -1.098901e-32  1.098901e-32   \n",
              "...   ...  ...  ...  ...  ...  ...   ...   ...           ...           ...   \n",
              "1755  0.3 -1.0  0.3 -0.7  1.0  0.5 -0.45 -0.84  6.296296e-01  1.000000e+00   \n",
              "1756  0.3 -1.0  0.3 -0.7  1.0  0.5 -0.45 -0.84  6.296296e-01  4.444444e-01   \n",
              "1757  0.3 -1.0  0.3 -0.7  1.0  0.5 -0.45 -0.84  6.296296e-01  4.444444e-01   \n",
              "1758  0.3 -1.0  0.3 -0.7  1.0  0.5 -0.45 -0.84  6.296296e-01  4.444444e-01   \n",
              "1759  0.3 -1.0  0.3 -0.7  1.0  0.5 -0.45 -0.84  4.444444e-01  8.148148e-01   \n",
              "\n",
              "      ...            14            15        16        17        18        19  \\\n",
              "0     ...  2.014652e-32  1.648352e-32  0.240741  0.018519 -0.018519 -0.240741   \n",
              "1     ...  2.426740e-32  2.152015e-32  0.236111 -0.041667  0.041667 -0.236111   \n",
              "2     ...  2.838828e-32  2.655678e-32  0.231481 -0.101852  0.101852 -0.231481   \n",
              "3     ...  3.250916e-32  3.159341e-32  0.226852 -0.162037  0.162037 -0.226852   \n",
              "4     ...  3.663004e-32  3.663004e-32  0.222222 -0.222222  0.222222 -0.222222   \n",
              "...   ...           ...           ...       ...       ...       ...       ...   \n",
              "1755  ...  1.250149e-32  3.403757e-32 -0.186834  0.510843 -0.356210  0.032201   \n",
              "1756  ...  1.329838e-32  3.002760e-32  0.263563 -0.031368 -0.041492 -0.190703   \n",
              "1757  ...  1.739433e-32  3.379749e-32  0.235731 -0.100393  0.021188 -0.156526   \n",
              "1758  ...  2.149028e-32  3.756737e-32  0.207899 -0.169418  0.083868 -0.122349   \n",
              "1759  ...  1.218786e-33  1.797951e-32 -0.156355  0.601319 -0.433620 -0.011344   \n",
              "\n",
              "            20        21        22        23  \n",
              "0     0.666667  0.074074 -0.407407 -0.333333  \n",
              "1     0.685185  0.240741 -0.490741 -0.435185  \n",
              "2     0.703704  0.407407 -0.574074 -0.537037  \n",
              "3     0.722222  0.574074 -0.657407 -0.638889  \n",
              "4     0.740741  0.740741 -0.740741 -0.740741  \n",
              "...        ...       ...       ...       ...  \n",
              "1755  0.566906  0.374217 -0.252808 -0.688315  \n",
              "1756  0.737314  0.138834 -0.268923 -0.607225  \n",
              "1757  0.745998  0.289214 -0.351752 -0.683460  \n",
              "1758  0.754682  0.439595 -0.434581 -0.759696  \n",
              "1759  0.376984  0.011248 -0.024647 -0.363586  \n",
              "\n",
              "[1760 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d743d1a9-a1b6-4b72-92f4-73449e164c0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.190476e-32</td>\n",
              "      <td>-9.157509e-34</td>\n",
              "      <td>...</td>\n",
              "      <td>2.014652e-32</td>\n",
              "      <td>1.648352e-32</td>\n",
              "      <td>0.240741</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>-0.018519</td>\n",
              "      <td>-0.240741</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>-0.407407</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.167582e-32</td>\n",
              "      <td>2.060440e-33</td>\n",
              "      <td>...</td>\n",
              "      <td>2.426740e-32</td>\n",
              "      <td>2.152015e-32</td>\n",
              "      <td>0.236111</td>\n",
              "      <td>-0.041667</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>-0.236111</td>\n",
              "      <td>0.685185</td>\n",
              "      <td>0.240741</td>\n",
              "      <td>-0.490741</td>\n",
              "      <td>-0.435185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.144689e-32</td>\n",
              "      <td>5.036630e-33</td>\n",
              "      <td>...</td>\n",
              "      <td>2.838828e-32</td>\n",
              "      <td>2.655678e-32</td>\n",
              "      <td>0.231481</td>\n",
              "      <td>-0.101852</td>\n",
              "      <td>0.101852</td>\n",
              "      <td>-0.231481</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>-0.574074</td>\n",
              "      <td>-0.537037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.121795e-32</td>\n",
              "      <td>8.012820e-33</td>\n",
              "      <td>...</td>\n",
              "      <td>3.250916e-32</td>\n",
              "      <td>3.159341e-32</td>\n",
              "      <td>0.226852</td>\n",
              "      <td>-0.162037</td>\n",
              "      <td>0.162037</td>\n",
              "      <td>-0.226852</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>-0.657407</td>\n",
              "      <td>-0.638889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-1.098901e-32</td>\n",
              "      <td>1.098901e-32</td>\n",
              "      <td>...</td>\n",
              "      <td>3.663004e-32</td>\n",
              "      <td>3.663004e-32</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>-0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>-0.222222</td>\n",
              "      <td>0.740741</td>\n",
              "      <td>0.740741</td>\n",
              "      <td>-0.740741</td>\n",
              "      <td>-0.740741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>0.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>6.296296e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.250149e-32</td>\n",
              "      <td>3.403757e-32</td>\n",
              "      <td>-0.186834</td>\n",
              "      <td>0.510843</td>\n",
              "      <td>-0.356210</td>\n",
              "      <td>0.032201</td>\n",
              "      <td>0.566906</td>\n",
              "      <td>0.374217</td>\n",
              "      <td>-0.252808</td>\n",
              "      <td>-0.688315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1756</th>\n",
              "      <td>0.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>6.296296e-01</td>\n",
              "      <td>4.444444e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.329838e-32</td>\n",
              "      <td>3.002760e-32</td>\n",
              "      <td>0.263563</td>\n",
              "      <td>-0.031368</td>\n",
              "      <td>-0.041492</td>\n",
              "      <td>-0.190703</td>\n",
              "      <td>0.737314</td>\n",
              "      <td>0.138834</td>\n",
              "      <td>-0.268923</td>\n",
              "      <td>-0.607225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1757</th>\n",
              "      <td>0.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>6.296296e-01</td>\n",
              "      <td>4.444444e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.739433e-32</td>\n",
              "      <td>3.379749e-32</td>\n",
              "      <td>0.235731</td>\n",
              "      <td>-0.100393</td>\n",
              "      <td>0.021188</td>\n",
              "      <td>-0.156526</td>\n",
              "      <td>0.745998</td>\n",
              "      <td>0.289214</td>\n",
              "      <td>-0.351752</td>\n",
              "      <td>-0.683460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1758</th>\n",
              "      <td>0.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>6.296296e-01</td>\n",
              "      <td>4.444444e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.149028e-32</td>\n",
              "      <td>3.756737e-32</td>\n",
              "      <td>0.207899</td>\n",
              "      <td>-0.169418</td>\n",
              "      <td>0.083868</td>\n",
              "      <td>-0.122349</td>\n",
              "      <td>0.754682</td>\n",
              "      <td>0.439595</td>\n",
              "      <td>-0.434581</td>\n",
              "      <td>-0.759696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1759</th>\n",
              "      <td>0.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>4.444444e-01</td>\n",
              "      <td>8.148148e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.218786e-33</td>\n",
              "      <td>1.797951e-32</td>\n",
              "      <td>-0.156355</td>\n",
              "      <td>0.601319</td>\n",
              "      <td>-0.433620</td>\n",
              "      <td>-0.011344</td>\n",
              "      <td>0.376984</td>\n",
              "      <td>0.011248</td>\n",
              "      <td>-0.024647</td>\n",
              "      <td>-0.363586</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1760 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d743d1a9-a1b6-4b72-92f4-73449e164c0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d743d1a9-a1b6-4b72-92f4-73449e164c0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d743d1a9-a1b6-4b72-92f4-73449e164c0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15682886-624b-4b75-be40-deebdb2b96fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15682886-624b-4b75-be40-deebdb2b96fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15682886-624b-4b75-be40-deebdb2b96fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e545717b-586a-46d2-b920-26c0fdf8597a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('my_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e545717b-586a-46d2-b920-26c0fdf8597a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('my_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "my_df"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "my_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "b_-ESzexfven"
      },
      "outputs": [],
      "source": [
        "# Assuming my_df has 44 columns\n",
        "X = my_df.iloc[:, :16]  # Select the first 8 columns (Coord): input\n",
        "y = my_df.iloc[:, 16:]   # Select the last 36 columns (Ke): output\n",
        "#convert to numpy arrays\n",
        "#Data used in the NN\n",
        "X = X.values\n",
        "y = y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bPZ3xi0E03Z8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2o3Cwlv4gr4L"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KSJSEmzahC20"
      },
      "outputs": [],
      "source": [
        "#Train Test Slip\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Bnh-wJd9hOPs"
      },
      "outputs": [],
      "source": [
        "# Convert your datasets to PyTorch tensors\n",
        "X_train = torch.FloatTensor(X_train)  # Inputs should be Float\n",
        "X_test = torch.FloatTensor(X_test)    # Inputs should be Float\n",
        "\n",
        "# If y_train and y_test are initially NumPy arrays\n",
        "y_train = np.array(y_train, dtype=float)  # Ensure they are float arrays\n",
        "y_test = np.array(y_test, dtype=float)    # Ensure they are float arrays\n",
        "\n",
        "# Convert to PyTorch FloatTensor\n",
        "y_train = torch.FloatTensor(y_train)  # Convert to FloatTensor\n",
        "y_test = torch.FloatTensor(y_test)    # Convert to FloatTensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X train: {X_train}')\n",
        "print(f'X test: {X_test}')\n",
        "print(f'y train: {y_train}')\n",
        "print(f'y test: {y_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO93VPZ5ty_B",
        "outputId": "5cab62aa-cfb9-4300-a044-ec86607147e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train: tensor([[ 5.0000e-01, -5.0000e-01,  5.0000e-01,  ...,  3.7037e-01,\n",
            "          1.3507e-32,  3.5027e-32],\n",
            "        [ 5.0000e-01, -3.0000e-01,  5.0000e-01,  ...,  2.2963e-01,\n",
            "          1.3104e-32,  1.1074e-32],\n",
            "        [ 2.6000e-01, -2.6000e-01,  2.6000e-01,  ...,  5.9259e-01,\n",
            "          1.8864e-32,  4.1941e-32],\n",
            "        ...,\n",
            "        [ 2.6000e-01, -2.6000e-01,  2.6000e-01,  ...,  5.9259e-01,\n",
            "          1.7582e-32,  3.3700e-32],\n",
            "        [ 5.0000e-01, -3.0000e-01,  5.0000e-01,  ...,  8.1481e-02,\n",
            "          1.7099e-33,  4.5929e-33],\n",
            "        [ 2.6000e-01, -2.6000e-01,  2.6000e-01,  ...,  5.9259e-01,\n",
            "          2.1978e-32,  3.8095e-32]])\n",
            "X test: tensor([[ 2.6000e-01, -2.6000e-01,  2.6000e-01,  ...,  4.4444e-01,\n",
            "          1.8681e-32,  3.4066e-32],\n",
            "        [ 2.6000e-01, -2.6000e-01,  2.6000e-01,  ...,  4.4444e-01,\n",
            "          1.5751e-32,  3.5531e-32],\n",
            "        [ 3.0000e-01, -1.0000e+00,  3.0000e-01,  ...,  6.2963e-01,\n",
            "          6.0012e-33,  2.4120e-32],\n",
            "        ...,\n",
            "        [ 3.0000e-01, -1.0000e+00,  3.0000e-01,  ...,  4.4444e-01,\n",
            "         -6.9928e-35,  2.8715e-32],\n",
            "        [ 2.6000e-01, -2.6000e-01,  2.6000e-01,  ...,  5.9259e-01,\n",
            "          1.8498e-32,  2.7656e-32],\n",
            "        [ 3.0000e-01, -1.0000e+00,  3.0000e-01,  ...,  8.1481e-01,\n",
            "          1.7704e-32,  3.3964e-32]])\n",
            "y train: tensor([[ 0.5324, -0.0139, -0.0694,  ...,  0.1898, -0.2731, -0.7083],\n",
            "        [ 0.1206, -0.0410,  0.0293,  ...,  0.1833, -0.2650, -0.2239],\n",
            "        [ 0.5185, -0.0519, -0.0148,  ...,  0.3815, -0.3815, -0.8481],\n",
            "        ...,\n",
            "        [ 0.2852, -0.0259,  0.0259,  ...,  0.4222, -0.3556, -0.6815],\n",
            "        [ 0.0068,  0.0671, -0.0503,  ...,  0.0195, -0.0346, -0.0929],\n",
            "        [ 0.7148, -0.4556,  0.1889,  ...,  0.5111, -0.4444, -0.7704]])\n",
            "y test: tensor([[ 0.7185, -0.4074,  0.1407,  ...,  0.3778, -0.3778, -0.6889],\n",
            "        [ 0.3889,  0.0778, -0.0778,  ...,  0.2519, -0.3185, -0.7185],\n",
            "        [-0.2509,  0.7573, -0.5053,  ...,  0.1013, -0.1214, -0.4878],\n",
            "        ...,\n",
            "        [ 0.2445,  0.2575, -0.3376,  ..., -0.0636,  0.0014, -0.5807],\n",
            "        [ 0.2667, -0.2148,  0.1481,  ...,  0.5074, -0.3741, -0.5593],\n",
            "        [ 0.1662, -0.1508,  0.0589,  ...,  0.4309, -0.3580, -0.6868]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItQlD6OQC7mD"
      },
      "source": [
        "**Normalized Dataset Z-norm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QenM3pAjhU9Z"
      },
      "outputs": [],
      "source": [
        "#Set the criterion of model to measure the error\n",
        "criterion = nn.MSELoss()  # Use MSE loss for regression\n",
        "#Choose an Optimizer - Adam Optimizer, learning rate (lr).\n",
        "#learning rate is used in case the error does not go down\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WLp2cRUBhYo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eed739b-3670-45b9-ed2b-ba6471a5fde5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 0.1691734939813614\n",
            "Epoch: 10 Loss: 0.1334717869758606\n",
            "Epoch: 20 Loss: 0.09719375520944595\n",
            "Epoch: 30 Loss: 0.059204623103141785\n",
            "Epoch: 40 Loss: 0.045712389051914215\n",
            "Epoch: 50 Loss: 0.03987076133489609\n",
            "Epoch: 60 Loss: 0.037075672298669815\n",
            "Epoch: 70 Loss: 0.03345021978020668\n",
            "Epoch: 80 Loss: 0.029394978657364845\n",
            "Epoch: 90 Loss: 0.024858687072992325\n",
            "Epoch: 100 Loss: 0.019574115052819252\n",
            "Epoch: 110 Loss: 0.013972640968859196\n",
            "Epoch: 120 Loss: 0.009861334227025509\n",
            "Epoch: 130 Loss: 0.007868201471865177\n",
            "Epoch: 140 Loss: 0.006441737525165081\n",
            "Epoch: 150 Loss: 0.005120893940329552\n",
            "Epoch: 160 Loss: 0.003941643517464399\n",
            "Epoch: 170 Loss: 0.0030084208119660616\n",
            "Epoch: 180 Loss: 0.0024227690882980824\n",
            "Epoch: 190 Loss: 0.0020855169277638197\n",
            "Epoch: 200 Loss: 0.0018385382136330009\n",
            "Epoch: 210 Loss: 0.0016310788923874497\n",
            "Epoch: 220 Loss: 0.0014628798235207796\n",
            "Epoch: 230 Loss: 0.0013199017848819494\n",
            "Epoch: 240 Loss: 0.0011932789348065853\n",
            "Epoch: 250 Loss: 0.0010803192853927612\n",
            "Epoch: 260 Loss: 0.0009802194545045495\n",
            "Epoch: 270 Loss: 0.000893254007678479\n",
            "Epoch: 280 Loss: 0.0008185267215594649\n",
            "Epoch: 290 Loss: 0.0007552843890152872\n",
            "Epoch: 300 Loss: 0.0007021866622380912\n",
            "Epoch: 310 Loss: 0.000657664320897311\n",
            "Epoch: 320 Loss: 0.0006201544310897589\n",
            "Epoch: 330 Loss: 0.0005883428384549916\n",
            "Epoch: 340 Loss: 0.0005612010136246681\n",
            "Epoch: 350 Loss: 0.0005378316855058074\n",
            "Epoch: 360 Loss: 0.0005173010868020356\n",
            "Epoch: 370 Loss: 0.0004988968139514327\n",
            "Epoch: 380 Loss: 0.00048207692452706397\n",
            "Epoch: 390 Loss: 0.00046643163659609854\n"
          ]
        }
      ],
      "source": [
        "#Train the model:\n",
        "# Epochs: (one run through all the training data in the network)\n",
        "epochs = 400\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "    # Forward pass: use normalized X_train as input\n",
        "    y_pred = model.forward(X_train)  # Use normalized inputs\n",
        "\n",
        "    # Measure the loss/error using normalized y_train\n",
        "    loss = criterion(y_pred, y_train)  # Compare with normalized targets\n",
        "\n",
        "    # Keep track of losses\n",
        "    losses.append(loss.detach().numpy())\n",
        "\n",
        "    # Print the losses (for tracking training progress)\n",
        "    if i % 10 == 0:\n",
        "        print(f'Epoch: {i} Loss: {loss}')\n",
        "\n",
        "    # Backpropagation: update the model's weights\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "fJNsQXmxkFix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "313f7b27-575a-40bb-e347-d45b5eda4a27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plot Loss\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.ylabel('Loss/error')\n",
        "plt.xlabel('Epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "h7WHYWMEp2FQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed3c5fc-45d7-4a3d-bde1-460c3155fd2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.0148\n",
            "MSE: 0.0005\n",
            "R-squared: 0.9963\n"
          ]
        }
      ],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient calculation\n",
        "with torch.no_grad():\n",
        "    # Get predictions\n",
        "    y_preds = model(X_test)\n",
        "\n",
        "    # Calculate Mean Absolute Error (MAE)\n",
        "    mae = torch.mean(torch.abs(y_preds - y_test))\n",
        "    print(f'MAE: {mae.item():.4f}')\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE)\n",
        "    mse = torch.mean((y_preds - y_test) ** 2)\n",
        "    print(f'MSE: {mse.item():.4f}')\n",
        "\n",
        "    # Calculate R-squared\n",
        "    ss_total = torch.sum((y_test - torch.mean(y_test)) ** 2)\n",
        "    ss_residual = torch.sum((y_test - y_preds) ** 2)\n",
        "    r_squared = 1 - (ss_residual / ss_total)\n",
        "    print(f'R-squared: {r_squared.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = torch.tensor([[0.3, -1, 0.3, -0.7, 1, 0.5, -0.45, -0.84, 0.6296, 0.4444, 0, 0, 0.8148, 1, 0, 0]])\n",
        "max_norm = 66758.24\n",
        "\n",
        "# Disable gradient calculation\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    # Prediction for new input\n",
        "    y_pred = model(new_input)\n",
        "    y_pred_real = y_pred * max_norm\n",
        "    print(f'Prediction: {y_pred_real}')\n",
        "\n",
        "\n",
        "    # Print the denormalized prediction\n",
        "    print(f' Prediction: {y_pred}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dA-zUOzbdjp",
        "outputId": "991ab387-052c-4d3b-f908-49bc55a19a74"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: tensor([[ 14297.2861,  -8473.4209,   2978.2234,  -8767.8086,  48372.6406,\n",
            "          41532.5234, -34255.1523, -56190.7266]])\n",
            " Prediction: tensor([[ 0.2142, -0.1269,  0.0446, -0.1313,  0.7246,  0.6221, -0.5131, -0.8417]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LkyK9RTrAD1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8ade9b-eeb7-45da-ee08-1e9137cc0093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: fc1.weight, Weights: [[ 0.25236     0.16918877  0.00265744  0.1965913  -0.02832526  0.08395796\n",
            "  -0.18621014  0.13291925  0.321674   -0.19668016  0.21729904  0.04678982\n",
            "   0.3085686   0.10047468  0.12054703 -0.03529775]\n",
            " [ 0.19272146  0.03695223 -0.11670998  0.06372458 -0.11518416 -0.02931821\n",
            "  -0.10153958  0.16584274 -0.19734254 -0.11525258 -0.07059368 -0.15031812\n",
            "   0.02359578 -0.24691978  0.22577727 -0.21236706]\n",
            " [ 0.22650723  0.00531636 -0.04767583  0.12493061  0.07056264  0.22836086\n",
            "  -0.01020289 -0.10296484  0.15771976 -0.08195899  0.10521439  0.22320554\n",
            "   0.27138248 -0.09059316  0.14431617  0.04473156]\n",
            " [ 0.12695876 -0.15237626 -0.24747711 -0.09659013 -0.19175571  0.20513472\n",
            "   0.07200783  0.10355338  0.07906529 -0.00434899  0.19565207 -0.1776284\n",
            "   0.01574093 -0.17063504  0.077088   -0.08609557]\n",
            " [ 0.13490193 -0.08070279  0.2656458  -0.16153955 -0.14187667 -0.13886546\n",
            "   0.1579647   0.10166725  0.36006936 -0.2773623  -0.24796903 -0.19559094\n",
            "  -0.12063809  0.20908102  0.08951896  0.2077311 ]\n",
            " [-0.09708992 -0.17761803  0.1646609  -0.10942631  0.15203626 -0.04707556\n",
            "   0.11141909 -0.19001278 -0.12143327  0.17181902  0.05285189 -0.06373969\n",
            "   0.2654222   0.3222164  -0.18129334 -0.13346705]\n",
            " [ 0.1984776  -0.12224452 -0.11906677 -0.25809526 -0.10217095  0.06138524\n",
            "  -0.01617241 -0.21444827  0.04826982 -0.14349239 -0.21209916 -0.13766566\n",
            "  -0.14833038 -0.22883402  0.24990222  0.04721874]\n",
            " [ 0.06118695 -0.21080667 -0.18004648 -0.06286983  0.01682954 -0.23842414\n",
            "  -0.08965944 -0.12847398 -0.0264012  -0.11617587 -0.01732394 -0.16940743\n",
            "  -0.19457057 -0.16869009 -0.08557436 -0.19732022]\n",
            " [ 0.22229034 -0.03957898  0.22777206  0.0740346  -0.21763213  0.18265167\n",
            "  -0.07645032 -0.09877089 -0.1012267  -0.29202953  0.07152766 -0.05461097\n",
            "   0.21862125 -0.19412804  0.18560728 -0.18351343]\n",
            " [ 0.03056664  0.01714113  0.20279796  0.16490123  0.25044763 -0.15689644\n",
            "  -0.01027768 -0.11747261 -0.01770211 -0.26494887  0.22771466 -0.18348762\n",
            "   0.24575293  0.17271836  0.08123899 -0.13516155]\n",
            " [ 0.24977097  0.02571155  0.0546933  -0.24150191  0.12963724 -0.02047519\n",
            "  -0.14185365  0.19814225  0.11389491 -0.13610564 -0.12653473 -0.01193893\n",
            "   0.25709334 -0.00720682 -0.14264372 -0.08561072]\n",
            " [-0.18481244  0.07069992  0.19546632 -0.23850724  0.06902964  0.12423826\n",
            "   0.03438408 -0.08583362  0.18306229  0.19098555  0.09348181 -0.04393035\n",
            "  -0.00773805  0.10304381 -0.04416353 -0.07450026]\n",
            " [ 0.17416751  0.20612156 -0.01038364 -0.08544324  0.02864885  0.02273612\n",
            "   0.05619591  0.01980841 -0.22699583 -0.03977874  0.21053237  0.09738874\n",
            "  -0.03306483 -0.17343992 -0.15295127 -0.22394171]\n",
            " [-0.08149061  0.08442605  0.15940541  0.11542434 -0.22098601 -0.15034062\n",
            "  -0.03945416  0.24183738  0.03616437 -0.06474268  0.10342881 -0.09522039\n",
            "  -0.16181391  0.18247181 -0.11367545 -0.05011669]\n",
            " [-0.13683257  0.12880996  0.30127683  0.01925309 -0.13560165 -0.15713987\n",
            "  -0.30308604  0.13000822  0.21122716  0.2524197   0.13096747  0.06327304\n",
            "   0.20211785 -0.23360714 -0.21419305 -0.23383716]\n",
            " [ 0.08276965 -0.14845094 -0.06988396 -0.1548479  -0.01810023 -0.1763831\n",
            "  -0.15299396  0.06123022 -0.01478489  0.20096442 -0.08020219 -0.18339181\n",
            "   0.04099937 -0.16670066 -0.0764854  -0.2379989 ]\n",
            " [ 0.07143102 -0.21273102  0.0572127   0.094452    0.23022132 -0.19505408\n",
            "   0.23233563 -0.17306805  0.09643245  0.29608136 -0.03525797 -0.00193337\n",
            "  -0.08141398 -0.32958665  0.11997572 -0.24817947]\n",
            " [ 0.14701796  0.18729523  0.22824462 -0.0507855  -0.21002904  0.0451071\n",
            "   0.14270702 -0.23773123  0.01551468 -0.2000423  -0.02186593 -0.12305337\n",
            "  -0.10533763 -0.04647432 -0.23757601  0.20512688]\n",
            " [ 0.22164626 -0.06448668 -0.01640709 -0.11599136 -0.20673054 -0.23405701\n",
            "   0.07572291 -0.14818816 -0.13652429  0.05106413 -0.08325279 -0.08088019\n",
            "   0.09908538  0.00238909 -0.08607811 -0.11970147]\n",
            " [-0.20345685  0.2096268  -0.10004678  0.06624487 -0.08674148  0.02031532\n",
            "   0.23307511  0.11518067 -0.21664992  0.0992257   0.23731071  0.06577083\n",
            "   0.16760617  0.24647188 -0.03830725  0.05188861]\n",
            " [-0.17375877 -0.05151927  0.18514594  0.12816146 -0.15819725 -0.20047125\n",
            "  -0.17084092 -0.24671942 -0.19290975 -0.06182435  0.16871929  0.04184556\n",
            "  -0.19015136 -0.20055598  0.12436882 -0.18596032]\n",
            " [-0.03095848  0.08412372 -0.11587958 -0.04127612  0.00713956 -0.05790021\n",
            "  -0.13923152 -0.23501785 -0.17995046 -0.03650388  0.24145943 -0.12075368\n",
            "  -0.17754678  0.20393573  0.06890258  0.13697743]\n",
            " [ 0.26608607  0.1372557  -0.17181939  0.00776498  0.13821964  0.00600318\n",
            "  -0.21638249  0.26033813 -0.1360368  -0.06808116 -0.22538877  0.01116708\n",
            "   0.07050179  0.17583363  0.04943743 -0.18959686]\n",
            " [-0.21546818 -0.0219904   0.24596201  0.12467538 -0.12221458 -0.01668402\n",
            "  -0.2063211  -0.13781554  0.10324375  0.19427358  0.20709231 -0.22952652\n",
            "   0.27343398 -0.15500991  0.09361681  0.21156132]\n",
            " [ 0.0030768   0.23585272 -0.21344668 -0.08809251  0.13741276 -0.06022595\n",
            "  -0.04615542 -0.09622129  0.17179401  0.1126625   0.08011252 -0.14049092\n",
            "  -0.20962793  0.01977821  0.07406971 -0.11542797]\n",
            " [ 0.01424238  0.18066454  0.10410668  0.00133436 -0.08920654 -0.1957432\n",
            "  -0.31824762 -0.09117189 -0.20344219  0.21816546 -0.07277769 -0.09780553\n",
            "   0.3816318   0.26731354  0.17822558 -0.12102818]\n",
            " [-0.1021167   0.09188512 -0.16656879 -0.16342601 -0.01207492 -0.09144017\n",
            "  -0.1874145   0.14828974  0.20104071  0.04055583 -0.04352832 -0.23156825\n",
            "  -0.09105968  0.06364641  0.11788273 -0.03160438]\n",
            " [-0.06080805  0.10532699 -0.16106987  0.1042702  -0.04843275  0.06682832\n",
            "  -0.07661343 -0.04275227 -0.08002304  0.21121448 -0.00649929  0.19514987\n",
            "   0.3299303  -0.17384936 -0.18237728  0.2005755 ]\n",
            " [ 0.1804796  -0.20322058 -0.03474972 -0.24869567 -0.19265915  0.04378818\n",
            "   0.07615225  0.04612742 -0.1266173   0.360207    0.03574449 -0.1475212\n",
            "  -0.05641199  0.15046337  0.08754817 -0.17677021]\n",
            " [ 0.06416986 -0.10119873 -0.23726282 -0.10919224  0.2147077   0.18562146\n",
            "   0.25270325  0.17342448  0.16414617 -0.06318243 -0.13755697  0.12491414\n",
            "  -0.15024117 -0.18415844 -0.07983351  0.05246481]\n",
            " [ 0.1571046  -0.12682657 -0.11873599  0.01135249 -0.12288302 -0.14355925\n",
            "   0.09823312 -0.05779756  0.30347523  0.2907629   0.07477638  0.08603942\n",
            "   0.16396686  0.05651749 -0.01818311  0.00343603]\n",
            " [ 0.19407316  0.26265633  0.03592722 -0.10639786 -0.11145227 -0.09291666\n",
            "  -0.04732185  0.23648854  0.27373427  0.11073837 -0.18398288 -0.1341762\n",
            "   0.07030404  0.01715736  0.02056193 -0.22949287]]\n",
            "Layer: fc1.bias, Weights: [ 1.06008813e-01 -1.90718025e-01 -1.24394357e-01 -2.07845628e-01\n",
            "  2.15894058e-01 -2.06194073e-01  2.10300773e-01 -2.69283801e-02\n",
            "  1.87188517e-02  1.60458580e-01  1.65166290e-04  1.77454367e-01\n",
            "  2.97420651e-01 -2.17052519e-01  1.87140390e-01  6.78608343e-02\n",
            "  1.04026817e-01  5.22661805e-02  1.02975503e-01 -1.20266706e-01\n",
            " -3.19852829e-02  2.80344367e-01  1.76233858e-01  2.43550800e-02\n",
            " -2.39573374e-01  5.04605249e-02 -1.70243382e-01  2.44237721e-01\n",
            " -8.01327825e-02 -4.59238179e-02 -1.28786089e-02  8.47008750e-02]\n",
            "Layer: fc2.weight, Weights: [[ 0.2609522   0.01679718  0.19106801 ...  0.09412695  0.22451918\n",
            "   0.08367597]\n",
            " [ 0.05310646  0.0943905   0.03215228 ... -0.13018946 -0.10286876\n",
            "   0.04080158]\n",
            " [ 0.20687562  0.17070517  0.01654338 ... -0.1137571  -0.10174274\n",
            "   0.08874988]\n",
            " ...\n",
            " [ 0.08380941  0.06465919  0.12815613 ...  0.17464168  0.0128547\n",
            "  -0.0733109 ]\n",
            " [ 0.11564574  0.15458831  0.00498471 ...  0.23656727  0.3160109\n",
            "   0.21033064]\n",
            " [-0.08914182  0.12356434  0.11703781 ... -0.07466099 -0.09246746\n",
            "   0.01519396]]\n",
            "Layer: fc2.bias, Weights: [ 0.1585588   0.08721989  0.1081072   0.06801511  0.16863188  0.11501227\n",
            "  0.10810868 -0.02381006 -0.14635263 -0.08385655  0.06363747  0.16267653\n",
            " -0.06906743  0.17640123  0.00279878  0.03404257  0.01437651 -0.01629996\n",
            "  0.14837739  0.03325649  0.13695432 -0.11688658 -0.09107906  0.0351577\n",
            "  0.16940816  0.11150778  0.0603191  -0.17465389  0.09764422 -0.11669058\n",
            " -0.14631574  0.01869104 -0.11184756  0.16986208 -0.09608552  0.08736252\n",
            "  0.08015595 -0.07788415  0.12096026  0.0489203   0.12702458  0.1974622\n",
            " -0.07533612 -0.08255812  0.1318144   0.01965765  0.00076981  0.17008974\n",
            " -0.00750276  0.01652209  0.12837596  0.10073742 -0.11434179  0.03322946\n",
            " -0.13478105 -0.09600272  0.1005104  -0.04711316 -0.09004246  0.05232555\n",
            "  0.03414559 -0.10988737  0.02991685 -0.17120278]\n",
            "Layer: fc3.weight, Weights: [[ 0.08605579 -0.041871    0.03391911 ...  0.12153223  0.23312846\n",
            "   0.04168977]\n",
            " [ 0.0173549   0.19905595  0.17329459 ... -0.06758104 -0.11117113\n",
            "  -0.08543985]\n",
            " [ 0.06198778  0.09051923 -0.05350396 ... -0.07969649  0.16493098\n",
            "   0.05725507]\n",
            " ...\n",
            " [ 0.07692513  0.024037   -0.04050145 ... -0.04522049  0.326183\n",
            "  -0.1048339 ]\n",
            " [-0.02437234 -0.03373954 -0.0747465  ...  0.08605984 -0.06965144\n",
            "   0.08954726]\n",
            " [-0.05107189  0.05837065  0.05800604 ...  0.01276472  0.03731542\n",
            "   0.03220665]]\n",
            "Layer: fc3.bias, Weights: [ 0.10857576  0.0354555   0.07199308  0.09708638 -0.02283362 -0.06110324\n",
            "  0.12312496  0.08621513 -0.0883917   0.07853635 -0.12259428 -0.06786534\n",
            "  0.02661406  0.09289923 -0.02822436  0.07984119  0.158287    0.13223329\n",
            " -0.11611307  0.04107035 -0.01883918  0.08281811  0.02656358  0.02611241\n",
            "  0.09746215  0.01042885 -0.07569943  0.15559226 -0.0027892   0.12123956\n",
            " -0.12188649 -0.06200119]\n",
            "Layer: out.weight, Weights: [[ 0.16730659 -0.02383805  0.1189564  -0.12244436  0.34995797 -0.07192327\n",
            "   0.0149284  -0.06309225 -0.25718063 -0.15635756 -0.1547305  -0.03611473\n",
            "  -0.05724981  0.17455137 -0.00085529  0.15688471  0.03455207  0.11792748\n",
            "   0.2437284  -0.21575038 -0.05359322  0.23705067  0.01815506 -0.04760843\n",
            "   0.07137983 -0.15626185  0.01271341 -0.08182012  0.05608055  0.01393675\n",
            "  -0.05931988 -0.08130958]\n",
            " [ 0.02794645  0.0974222  -0.22596395 -0.15091324 -0.31335798  0.07141361\n",
            "   0.11382907 -0.23552029  0.19667427  0.07644591 -0.09486412  0.03819295\n",
            "   0.11605575  0.19032925  0.07644273 -0.03793221 -0.16503201 -0.13057354\n",
            "   0.0823518   0.03151833  0.10459851 -0.30905637 -0.03906743 -0.0562236\n",
            "  -0.0187653   0.2446729   0.0051715  -0.0102555  -0.05991606 -0.26989368\n",
            "  -0.1601615   0.09080908]\n",
            " [-0.14466265  0.10073588 -0.03881854  0.04386151  0.22125134  0.02459217\n",
            "   0.02408315  0.18056107 -0.19447401  0.06452622 -0.14867376  0.16187371\n",
            "  -0.07512864 -0.06010503  0.09916957 -0.00794972  0.14502811 -0.06524297\n",
            "  -0.07608929  0.01481043 -0.12815864  0.11371669  0.2300462   0.11966571\n",
            "  -0.0913182  -0.1451482  -0.15931123 -0.12786183 -0.03658899 -0.10027108\n",
            "   0.10198479  0.07946158]\n",
            " [-0.1001673  -0.05990423  0.13235918 -0.03413649  0.11573838  0.15483053\n",
            "  -0.10411499 -0.210705    0.2416921  -0.14199188  0.16904698 -0.11285365\n",
            "   0.01282598 -0.00646478 -0.04175813  0.1176772  -0.20641544 -0.12971704\n",
            "  -0.09946715  0.07796323  0.05963578  0.08910128  0.01207996  0.15899804\n",
            "  -0.09660354 -0.09249946 -0.02427477  0.03209911 -0.05183988  0.0307671\n",
            "   0.04846675  0.02898761]\n",
            " [ 0.18290019  0.06955058  0.1494519  -0.02622297 -0.18005     0.11719121\n",
            "   0.11477682  0.19296001  0.18147205  0.04008954 -0.12759809 -0.16759971\n",
            "   0.05465916  0.1914885  -0.01374249 -0.03697806  0.12793668 -0.04958318\n",
            "   0.23760726 -0.40799892 -0.13807683 -0.07869292 -0.03487306  0.05960892\n",
            "   0.14195643 -0.13455416 -0.03630612  0.09683153 -0.03898484  0.03585547\n",
            "   0.11444627 -0.03808907]\n",
            " [ 0.10621767  0.18795326  0.09023234 -0.00978383 -0.0443958  -0.11261052\n",
            "  -0.02936612  0.09312276  0.04669743  0.00907172  0.1424547  -0.07001637\n",
            "   0.05250835 -0.09754751  0.04750167  0.16965784  0.07412019  0.06590868\n",
            "  -0.17205143 -0.14463654 -0.10157694 -0.17317757  0.30289966 -0.07374695\n",
            "  -0.0361625  -0.29379475 -0.04929236  0.1853864   0.03250042  0.02163332\n",
            "   0.09213756  0.14891683]\n",
            " [ 0.09350365 -0.21559644 -0.03030199 -0.16928692 -0.04353815  0.1260943\n",
            "  -0.1962549  -0.16905324 -0.09894637  0.11670557 -0.17172372 -0.1140705\n",
            "  -0.088685    0.0830943   0.10302036  0.08908609  0.06702618 -0.10303561\n",
            "  -0.02714884  0.19277418 -0.00584952 -0.03042802 -0.01243269  0.07894182\n",
            "  -0.08082394  0.2998191  -0.04578273 -0.02262705  0.16055915  0.05341094\n",
            "  -0.06437172 -0.09322253]\n",
            " [-0.00597444 -0.04008707 -0.02241177  0.0907435   0.08632103 -0.10756943\n",
            "  -0.1741027   0.13625777 -0.06187021 -0.10735335 -0.12983558  0.16975492\n",
            "   0.07012774 -0.15106888 -0.15267614  0.1329119   0.04142153 -0.07279018\n",
            "  -0.187244    0.20566991 -0.14220539  0.07613266 -0.27551386 -0.15761578\n",
            "  -0.20137665  0.2862579   0.16064385 -0.19168428  0.13665445 -0.1526481\n",
            "  -0.16428791  0.07215468]]\n",
            "Layer: out.bias, Weights: [ 0.11543652  0.06646182 -0.00101161  0.13584784 -0.12020425  0.10841816\n",
            " -0.09296012 -0.02233012]\n"
          ]
        }
      ],
      "source": [
        "# Extracting all weights and biases\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:  # Only if you want trainable parameters\n",
        "        print(f'Layer: {name}, Weights: {param.data.numpy()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JT4--XSfNmst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9442f5-70dd-4dfc-e18f-1e47d4de5487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights from fc1: [[ 0.25236     0.16918877  0.00265744  0.1965913  -0.02832526  0.08395796\n",
            "  -0.18621014  0.13291925  0.321674   -0.19668016  0.21729904  0.04678982\n",
            "   0.3085686   0.10047468  0.12054703 -0.03529775]\n",
            " [ 0.19272146  0.03695223 -0.11670998  0.06372458 -0.11518416 -0.02931821\n",
            "  -0.10153958  0.16584274 -0.19734254 -0.11525258 -0.07059368 -0.15031812\n",
            "   0.02359578 -0.24691978  0.22577727 -0.21236706]\n",
            " [ 0.22650723  0.00531636 -0.04767583  0.12493061  0.07056264  0.22836086\n",
            "  -0.01020289 -0.10296484  0.15771976 -0.08195899  0.10521439  0.22320554\n",
            "   0.27138248 -0.09059316  0.14431617  0.04473156]\n",
            " [ 0.12695876 -0.15237626 -0.24747711 -0.09659013 -0.19175571  0.20513472\n",
            "   0.07200783  0.10355338  0.07906529 -0.00434899  0.19565207 -0.1776284\n",
            "   0.01574093 -0.17063504  0.077088   -0.08609557]\n",
            " [ 0.13490193 -0.08070279  0.2656458  -0.16153955 -0.14187667 -0.13886546\n",
            "   0.1579647   0.10166725  0.36006936 -0.2773623  -0.24796903 -0.19559094\n",
            "  -0.12063809  0.20908102  0.08951896  0.2077311 ]\n",
            " [-0.09708992 -0.17761803  0.1646609  -0.10942631  0.15203626 -0.04707556\n",
            "   0.11141909 -0.19001278 -0.12143327  0.17181902  0.05285189 -0.06373969\n",
            "   0.2654222   0.3222164  -0.18129334 -0.13346705]\n",
            " [ 0.1984776  -0.12224452 -0.11906677 -0.25809526 -0.10217095  0.06138524\n",
            "  -0.01617241 -0.21444827  0.04826982 -0.14349239 -0.21209916 -0.13766566\n",
            "  -0.14833038 -0.22883402  0.24990222  0.04721874]\n",
            " [ 0.06118695 -0.21080667 -0.18004648 -0.06286983  0.01682954 -0.23842414\n",
            "  -0.08965944 -0.12847398 -0.0264012  -0.11617587 -0.01732394 -0.16940743\n",
            "  -0.19457057 -0.16869009 -0.08557436 -0.19732022]\n",
            " [ 0.22229034 -0.03957898  0.22777206  0.0740346  -0.21763213  0.18265167\n",
            "  -0.07645032 -0.09877089 -0.1012267  -0.29202953  0.07152766 -0.05461097\n",
            "   0.21862125 -0.19412804  0.18560728 -0.18351343]\n",
            " [ 0.03056664  0.01714113  0.20279796  0.16490123  0.25044763 -0.15689644\n",
            "  -0.01027768 -0.11747261 -0.01770211 -0.26494887  0.22771466 -0.18348762\n",
            "   0.24575293  0.17271836  0.08123899 -0.13516155]\n",
            " [ 0.24977097  0.02571155  0.0546933  -0.24150191  0.12963724 -0.02047519\n",
            "  -0.14185365  0.19814225  0.11389491 -0.13610564 -0.12653473 -0.01193893\n",
            "   0.25709334 -0.00720682 -0.14264372 -0.08561072]\n",
            " [-0.18481244  0.07069992  0.19546632 -0.23850724  0.06902964  0.12423826\n",
            "   0.03438408 -0.08583362  0.18306229  0.19098555  0.09348181 -0.04393035\n",
            "  -0.00773805  0.10304381 -0.04416353 -0.07450026]\n",
            " [ 0.17416751  0.20612156 -0.01038364 -0.08544324  0.02864885  0.02273612\n",
            "   0.05619591  0.01980841 -0.22699583 -0.03977874  0.21053237  0.09738874\n",
            "  -0.03306483 -0.17343992 -0.15295127 -0.22394171]\n",
            " [-0.08149061  0.08442605  0.15940541  0.11542434 -0.22098601 -0.15034062\n",
            "  -0.03945416  0.24183738  0.03616437 -0.06474268  0.10342881 -0.09522039\n",
            "  -0.16181391  0.18247181 -0.11367545 -0.05011669]\n",
            " [-0.13683257  0.12880996  0.30127683  0.01925309 -0.13560165 -0.15713987\n",
            "  -0.30308604  0.13000822  0.21122716  0.2524197   0.13096747  0.06327304\n",
            "   0.20211785 -0.23360714 -0.21419305 -0.23383716]\n",
            " [ 0.08276965 -0.14845094 -0.06988396 -0.1548479  -0.01810023 -0.1763831\n",
            "  -0.15299396  0.06123022 -0.01478489  0.20096442 -0.08020219 -0.18339181\n",
            "   0.04099937 -0.16670066 -0.0764854  -0.2379989 ]\n",
            " [ 0.07143102 -0.21273102  0.0572127   0.094452    0.23022132 -0.19505408\n",
            "   0.23233563 -0.17306805  0.09643245  0.29608136 -0.03525797 -0.00193337\n",
            "  -0.08141398 -0.32958665  0.11997572 -0.24817947]\n",
            " [ 0.14701796  0.18729523  0.22824462 -0.0507855  -0.21002904  0.0451071\n",
            "   0.14270702 -0.23773123  0.01551468 -0.2000423  -0.02186593 -0.12305337\n",
            "  -0.10533763 -0.04647432 -0.23757601  0.20512688]\n",
            " [ 0.22164626 -0.06448668 -0.01640709 -0.11599136 -0.20673054 -0.23405701\n",
            "   0.07572291 -0.14818816 -0.13652429  0.05106413 -0.08325279 -0.08088019\n",
            "   0.09908538  0.00238909 -0.08607811 -0.11970147]\n",
            " [-0.20345685  0.2096268  -0.10004678  0.06624487 -0.08674148  0.02031532\n",
            "   0.23307511  0.11518067 -0.21664992  0.0992257   0.23731071  0.06577083\n",
            "   0.16760617  0.24647188 -0.03830725  0.05188861]\n",
            " [-0.17375877 -0.05151927  0.18514594  0.12816146 -0.15819725 -0.20047125\n",
            "  -0.17084092 -0.24671942 -0.19290975 -0.06182435  0.16871929  0.04184556\n",
            "  -0.19015136 -0.20055598  0.12436882 -0.18596032]\n",
            " [-0.03095848  0.08412372 -0.11587958 -0.04127612  0.00713956 -0.05790021\n",
            "  -0.13923152 -0.23501785 -0.17995046 -0.03650388  0.24145943 -0.12075368\n",
            "  -0.17754678  0.20393573  0.06890258  0.13697743]\n",
            " [ 0.26608607  0.1372557  -0.17181939  0.00776498  0.13821964  0.00600318\n",
            "  -0.21638249  0.26033813 -0.1360368  -0.06808116 -0.22538877  0.01116708\n",
            "   0.07050179  0.17583363  0.04943743 -0.18959686]\n",
            " [-0.21546818 -0.0219904   0.24596201  0.12467538 -0.12221458 -0.01668402\n",
            "  -0.2063211  -0.13781554  0.10324375  0.19427358  0.20709231 -0.22952652\n",
            "   0.27343398 -0.15500991  0.09361681  0.21156132]\n",
            " [ 0.0030768   0.23585272 -0.21344668 -0.08809251  0.13741276 -0.06022595\n",
            "  -0.04615542 -0.09622129  0.17179401  0.1126625   0.08011252 -0.14049092\n",
            "  -0.20962793  0.01977821  0.07406971 -0.11542797]\n",
            " [ 0.01424238  0.18066454  0.10410668  0.00133436 -0.08920654 -0.1957432\n",
            "  -0.31824762 -0.09117189 -0.20344219  0.21816546 -0.07277769 -0.09780553\n",
            "   0.3816318   0.26731354  0.17822558 -0.12102818]\n",
            " [-0.1021167   0.09188512 -0.16656879 -0.16342601 -0.01207492 -0.09144017\n",
            "  -0.1874145   0.14828974  0.20104071  0.04055583 -0.04352832 -0.23156825\n",
            "  -0.09105968  0.06364641  0.11788273 -0.03160438]\n",
            " [-0.06080805  0.10532699 -0.16106987  0.1042702  -0.04843275  0.06682832\n",
            "  -0.07661343 -0.04275227 -0.08002304  0.21121448 -0.00649929  0.19514987\n",
            "   0.3299303  -0.17384936 -0.18237728  0.2005755 ]\n",
            " [ 0.1804796  -0.20322058 -0.03474972 -0.24869567 -0.19265915  0.04378818\n",
            "   0.07615225  0.04612742 -0.1266173   0.360207    0.03574449 -0.1475212\n",
            "  -0.05641199  0.15046337  0.08754817 -0.17677021]\n",
            " [ 0.06416986 -0.10119873 -0.23726282 -0.10919224  0.2147077   0.18562146\n",
            "   0.25270325  0.17342448  0.16414617 -0.06318243 -0.13755697  0.12491414\n",
            "  -0.15024117 -0.18415844 -0.07983351  0.05246481]\n",
            " [ 0.1571046  -0.12682657 -0.11873599  0.01135249 -0.12288302 -0.14355925\n",
            "   0.09823312 -0.05779756  0.30347523  0.2907629   0.07477638  0.08603942\n",
            "   0.16396686  0.05651749 -0.01818311  0.00343603]\n",
            " [ 0.19407316  0.26265633  0.03592722 -0.10639786 -0.11145227 -0.09291666\n",
            "  -0.04732185  0.23648854  0.27373427  0.11073837 -0.18398288 -0.1341762\n",
            "   0.07030404  0.01715736  0.02056193 -0.22949287]]\n"
          ]
        }
      ],
      "source": [
        "# Access weights directly from each layer\n",
        "weights_fc1 = model.fc1.weight.data.numpy()\n",
        "weights_fc2 = model.fc2.weight.data.numpy()\n",
        "#weights_fc3 = model.fc3.weight.data.numpy()\n",
        "weights_out = model.out.weight.data.numpy()\n",
        "\n",
        "print(\"Weights from fc1:\", weights_fc1)\n",
        "#print(\"Weights from fc2:\", weights_fc2)\n",
        "#print(\"Weights from fc3:\", weights_fc3)\n",
        "#print(\"Weights from output layer:\", weights_out)\n",
        "\n",
        "# Save weights to text files\n",
        "#np.savetxt('weights_fc1.txt', weights_fc1, fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('weights_fc2.txt', weights_fc2, fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('weights_fc3.txt', weights_fc3, fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('weights_output.txt', weights_out, fmt='%.6f', delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "m15nsjH-NrWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e541176e-93e1-4008-cc03-04dcda786b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biases from fc1: [ 1.06008813e-01 -1.90718025e-01 -1.24394357e-01 -2.07845628e-01\n",
            "  2.15894058e-01 -2.06194073e-01  2.10300773e-01 -2.69283801e-02\n",
            "  1.87188517e-02  1.60458580e-01  1.65166290e-04  1.77454367e-01\n",
            "  2.97420651e-01 -2.17052519e-01  1.87140390e-01  6.78608343e-02\n",
            "  1.04026817e-01  5.22661805e-02  1.02975503e-01 -1.20266706e-01\n",
            " -3.19852829e-02  2.80344367e-01  1.76233858e-01  2.43550800e-02\n",
            " -2.39573374e-01  5.04605249e-02 -1.70243382e-01  2.44237721e-01\n",
            " -8.01327825e-02 -4.59238179e-02 -1.28786089e-02  8.47008750e-02]\n",
            "Biases from fc2: [ 0.1585588   0.08721989  0.1081072   0.06801511  0.16863188  0.11501227\n",
            "  0.10810868 -0.02381006 -0.14635263 -0.08385655  0.06363747  0.16267653\n",
            " -0.06906743  0.17640123  0.00279878  0.03404257  0.01437651 -0.01629996\n",
            "  0.14837739  0.03325649  0.13695432 -0.11688658 -0.09107906  0.0351577\n",
            "  0.16940816  0.11150778  0.0603191  -0.17465389  0.09764422 -0.11669058\n",
            " -0.14631574  0.01869104 -0.11184756  0.16986208 -0.09608552  0.08736252\n",
            "  0.08015595 -0.07788415  0.12096026  0.0489203   0.12702458  0.1974622\n",
            " -0.07533612 -0.08255812  0.1318144   0.01965765  0.00076981  0.17008974\n",
            " -0.00750276  0.01652209  0.12837596  0.10073742 -0.11434179  0.03322946\n",
            " -0.13478105 -0.09600272  0.1005104  -0.04711316 -0.09004246  0.05232555\n",
            "  0.03414559 -0.10988737  0.02991685 -0.17120278]\n",
            "Biases from output layer: [ 0.11543652  0.06646182 -0.00101161  0.13584784 -0.12020425  0.10841816\n",
            " -0.09296012 -0.02233012]\n"
          ]
        }
      ],
      "source": [
        "# Access biases directly from each layer\n",
        "bias_fc1 = model.fc1.bias.data.numpy()\n",
        "bias_fc2 = model.fc2.bias.data.numpy()\n",
        "#bias_fc3 = model.fc3.bias.data.numpy()\n",
        "bias_out = model.out.bias.data.numpy()\n",
        "\n",
        "print(\"Biases from fc1:\", bias_fc1)\n",
        "print(\"Biases from fc2:\", bias_fc2)\n",
        "#print(\"Biases from fc3:\", bias_fc3)\n",
        "print(\"Biases from output layer:\", bias_out)\n",
        "\n",
        "#np.savetxt('Biases1.txt', bias_fc1.reshape(1, -1), fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('Biases2.txt', bias_fc2.reshape(1, -1), fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('Biases3.txt', bias_fc3.reshape(1, -1), fmt='%.6f', delimiter=',')\n",
        "#np.savetxt('BiasesOut.txt', bias_out.reshape(1, -1), fmt='%.6f', delimiter=',')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPDnIduY3x2mZWWvpy2b1LY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}